{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiverTwilight/Neural_Network/blob/master/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EzQhFI_imOU"
      },
      "source": [
        "# Overview\n",
        "\n",
        "> Created by **Rene Wang**\n",
        "\n",
        "This is a full example of how to detect hand-writting number with deep learning. The example is based on the MNIST dataset, which contains 60,000 training images and 10,000 testing images. Each image is a 28x28 grayscale image of a hand-written digit. The goal is to train a model to correctly classify the digit in the image.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/18B-Fujnr7uDhfyERZzWHTI3-31anw5OH?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "<a href=\"https://ibb.co/zXNKG13\"><img src=\"https://i.ibb.co/3pktBwx/0f63c745a964ec5cd2e85cda9cb656a.jpg\" alt=\"0f63c745a964ec5cd2e85cda9cb656a\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "RwXl6HSPOKEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2310b14f-11bd-442e-d50d-c818e678cbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.9/dist-packages (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install colorama\n",
        "is_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdTZJ42evAVC"
      },
      "source": [
        "## Dataset Process\n",
        "\n",
        "This will transform the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mc8rwDOo2Ts"
      },
      "source": [
        "### Use Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "-t2zz9-LQUTq"
      },
      "outputs": [],
      "source": [
        "#@title Custom Data Config\n",
        "min_therehold = 127 #@param {type:\"number\"}\n",
        "max_therehold = 255 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "tYhjEh7dZmQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0162291c-ffcd-4e19-a247-696df0b1320f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAM0lEQVR4nGNgGFjwH12ACY8csiQmIF8Sn3uINRZTI+1di89OLHLUsBOfsdjkqBMrgwMAAAD9CBdExnYLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYklEQVR4nM1QQQ7AMAhSs/9/mR2WdCpodhwnK4JYs48AWsNfqr2rjsXRjbr1vpjtH1wTkdPBHLWTS4gzgqZ0Ds4ZhxPaYtulcYTbRjUSPKiFq3I8RSKlBV3qyXH6W1fc/3AD5oscDdz+CcwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUklEQVR4nGNgIBcwQun/SGxs4P9/fKYQkEXjM+GTRZXEq5MUSRIchEcSw5tE24lPJ0mBh6yTRI0InRA51FhjgbMYMVMDcjLBSCeMcDl8KWiwAABryxQNfbH6mgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAT0lEQVR4nGNgIBcwovH/YxOESv1HkBhyaDR2A6A0Ex453BaTLodsKDY78Uni98hAyTIwMJDuFUKS/4nQiS1F/IcJY0r+RwhiMxZ7+qITAAAO4xr9MdIWfwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXElEQVR4nMWSOw7AMAhDMfe/M91SbKjVpaqnxC98FIgwQjuXGiAi73EQiqJENZw0rMUtMKf1quIduVa0af+AR9snWNoGUaFjoevEIbgpDdMd4qxpGC3YaAbP6DNdFwYWEWZyCpsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASklEQVR4nL2QSw4AQATFau5/Z7P1CWHDTqovgPsSBaSCgNomQsxAFQKg2kAcfA1rxWAuRG9GMSw0T3VmWmcc25n5yGns0pw/4ag+kiYQCzvgvtoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAV0lEQVR4nM2QQQqAQAwDJ+L/vxwPiyiYhj0a6GmYbrrwmxiAo7AqZnNHjOaWOLSdoRus2TTPKBrEmrxVAxRgNL+pXOhZlkw1WM27V/nb7x0A9prMPXrvXEr9FRY4bNf9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYklEQVR4nJ2ROxIAMQhCyd7/zqTYQuJvTCxlHooCTa3QoXW/RFtgYUUAIFOSOsyLh2WYqRsGEYJGUYwT0uB4hD9pQZqWXEi8bqO01eXszjd1TZ89AotnD0BPnuBFFL6SDsQGlaYaF/M+Ay4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAVklEQVR4nM2QQQoAIAgEV///ZztIGboFQQc9RaPbJNCgbDsrAJhR5hDCUzT3S4E81aGky4MjmcQUTgG6NEhyyFl0SYExe/g1f5OyvIRf8ObzEnvdf4ManU8UEPkwVeIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837D00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAALklEQVR4nGNgoAv4j8xhwieLIYlX56CWRAf4A4Fcyf/4JIl3D31C6D8OVUMCAAC1VwYbsVemZQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAS0lEQVR4nGNgGOTgPzKHCY8cuiTxpqLp/M/AwPD/Pw5JNIAmyYhbEtVGkoyFmgpzE7Il/9FVsWAxjRGLGKZ+UvyJ6h3SdFJHciAAAOj7DBrXBPJnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837D00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAARUlEQVR4nNWQQQoAIAgEx+j/X7ZbBcpmt/IkDOMuwivjDkCPYK0tYQaWm7btwTz3EeasdH22ZibQFaxF3maqx2uzCv+aAQm4ChpTFDF7AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nO2QQQoAIBACp/7/ZzsEtUFtec+TICoKHxRAgR8geVp96XZDL1oF0JyzoG9T4H7vJjrdGUQvNTgzo/3ROCF7YIsG0wQY+BvU3KgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837D00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQUlEQVR4nGNgGI7g/390ESZ8yhmRdGKIMWHKIQALdlMw7cRwEbLq/+gC6Eb9x2I6dsPhyqBaUHQiWP9xOHkU4AEAMTUNCv3JOAQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837EE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAP0lEQVR4nGNgoAlgROP/RxZiRJfCpgNZxX98VsElmfDIYZPEayg+K4mVQ7cTRR/WQMAiw8DwH+EYvAExCmgMAK2GD/1Bw0J1AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837D00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAATklEQVR4nOWQMQ4AIAgDi///cx3UICmwOtjBGA8PFPg19O1oGCyHcrwhz5Jo7wi0DgIEd4lCCwPnM5Xauicb8XpnddNcnWljncLib19nAu43FQciq6fwAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837670>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXElEQVR4nK2QQQ7AIAgEl8b/f3l7KAIJVFvaPWjMZBYV6EZ0JyAA7RxD+uo51KsMhTW7IOdcKeBd9lAQykszM4eEpDsP0+rXmJuK+0+Jte/Mh3D1CR9ql/l1Zj8ntqkSIQz5mQoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837580>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUUlEQVR4nOWQwQoAIAhDp/T/v2yXJkRjQdd2EudzIvCXSjXTeDTt0ndSt9N4FvSZ6baSlAMBoKJY7hocUWgfFMK+XruYM7NJlRltnCAx+12tCZPqEhEf/9cMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQklEQVR4nGNgGGSAEVPoP1ycCasORogKrJIwgE2SEbckwkpcxv7HJYnwABZJAl6Bmopd8j9OBzHC9GEHeCVHAdEAAK3rCRbekHq2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAK0lEQVR4nGNgGAXI4P9/dBEmYnViiODViZDE1EisThLdg9CJRY4qdg5vAABbfAYLYa58JwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASElEQVR4nO2QMQ4AIAgDi/H/X64DBhOLbGx27HEhKfDTH2o1qvvx1ALmDObMNjcxD1OTMKrlzQZUhpkqV5g9LUcIMyvLhZqyAKrYDw0XmhDQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQ0lEQVR4nGNgGAXDCTBiE/wPFWfCLocT/P8PwQwMLETahGkyNjvhtmKXxGMBzCdYJOEeYUR37X+Yjv/YdP4nwisQAADE5g0MwINPzAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAARUlEQVR4nO2PMQ4AMAgCpf//M13s0goxzmWEiEfEVKhMpr/KDEHXSJdS1Z5MhY2P75QkgaoFGlss0IA2eS2tuJs8+7q0AUULEQakRUNMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837370>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nO2QsQ0AIAzDUsT/L5cBAUtq9QAy1nIUVfopk5I0gKHIrKhtlDqzt8aYT4wKGnBY0odozRbZnF4OPyrt9VJ8UDMLWtQTA5J9E0sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837760>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXklEQVR4nN2QsRLAIAhDA9f//+U4WAWNOHYoE+ZdSE7gN2Nz4/JaIAEDN/oMtpkS5AkBnnax++hSne6UFNmCqi9lqvPVi7sIWaBfavZMKzLzJ4g/4K3sqWvEFaW+ngZlaRwLxx9ocAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837370>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASUlEQVR4nGNgGEqAEUPkP0KUCV3qP5J6FnRdjEjGsWBK/cdq/38UCrsSvJIIJrpr8RqKIonhT2I1ouskXiOma3FL4jWVgOzgBgCkSRMIMZnwCAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837760>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUklEQVR4nNWQQRLAIAwCwen/v0yPCmkcj5abIeAq8F9JdnzqAsDGtGiaRKe4ctMZNcoJzSOgZTTCA5fySdtzfhOPfs0zGbSknLW+c/N9hwB36gXRPhUP5yafhgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAL0lEQVR4nGNgGNbgP4zBhE8WqyRenYNWEhvAHwh4JP/jkyTfQdQwlkTJ/1hUkQwA9l0GGwZKkvwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678837370>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGNgGFzgP9NAu2AUjALsAACh5AECYu2K4QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66A78D1CD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAS0lEQVR4nOWPORIAIAjEguP/v4yFR+OCNlZuSSYLwJOYHjtgFIm8S1Va1js3OJCH20K4tiYQQF+blk6o/7wQpXklBtfGMG090N/SAL1KEwicha77AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66A78D1CD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAPElEQVR4nGNgwAMYkTn/0fiMKFIYylHB///47EGWZMIjhyGJ11B8VpIgx4RHDksgoAtD3fIfm7JRMKQAAHyzD/36yWEAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66A78D1CD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXklEQVR4nOWQORLAMAgDBZP/f1lpEiMOu0sVKsPOgsbAJ2XxZG61I2BgptdiWVLIAQGuTdV9ZdmsfihZpya0eXqzme983husq36K6RKrbU2fUH2Bp7BDVgtrDvWHugH+tRwLMKVjpwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66A78D1CD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nO2QMQ4AIAwCqfH/X8bBaBdKGmcZezlCCvy8hQAwDLOiZ0Vto1SZvTXCTDEqKMBhdB9ya7bozanl0KMor5faB2UWM3wTA7Q8musAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66A78D1CD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUElEQVR4nNWQwQ4AMARDS/z/L9thE8tSnOeoWg/gv3KnbcsBQAqRWkN8TePKJvPEeRUsgelE1ThBSLg1nBcUodLJUxmhW2WseWfzvmHxH7UAePUVD5rD42QAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66A78D1CD0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASElEQVR4nOWPQQoAIAgE1+j/X94ukVBqWcf2ojDsiMDHYZ8lYCY8slpNAiC3WguKD6lrVtutpPoNq1RPubTmfvrPcfii+QzDNJBoDBpJye3PAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  array([1, 8, 2, 3, 5, 7, 6, 9, 4, 1, 4, 7, 3, 5, 2, 8, 9, 6, 0, 1, 4, 2,\n",
              "         3, 6, 8, 7, 5])),\n",
              " (array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  array([1, 3, 7, 2, 8, 6, 5, 4])))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/Project/NeuralNetwork/data/train'\n",
        "test_data_path = '/content/drive/MyDrive/Project/NeuralNetwork/data/test'\n",
        "\n",
        "def read_file(data_path, one_hot_label, flatten=False):\n",
        "    img_size = 784\n",
        "\n",
        "    x_train = []\n",
        "    t_train = []\n",
        "\n",
        "    for foldername in os.listdir(data_path):\n",
        "        bundle_path = os.path.join(data_path, foldername)\n",
        "        if os.path.isdir(bundle_path):\n",
        "            for file_name in os.listdir(bundle_path):\n",
        "\n",
        "                file_type = str(file_name.split('.')[1])\n",
        "                if file_type != \"png\" and file_type != \"jpg\":\n",
        "                    continue\n",
        "\n",
        "                img = cv2.imread(os.path.join(bundle_path, file_name))\n",
        "                label = int(file_name.split('.')[0])\n",
        "\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                \n",
        "                retval, dst = cv2.threshold(gray, min_therehold, max_therehold, cv2.THRESH_OTSU)\n",
        "\n",
        "                dst = dst.astype(np.float32)\n",
        "\n",
        "                flattened_img = dst.flatten()\n",
        "                flattened_img = 255 - flattened_img\n",
        "\n",
        "                img_processed = flattened_img.reshape(dst.shape)\n",
        "                cv2_imshow(img_processed)\n",
        "\n",
        "                flattened_img /= 255.0\n",
        "\n",
        "                # print(flattened_img)\n",
        "                \n",
        "                x_train.append(flattened_img)\n",
        "\n",
        "                if one_hot_label:\n",
        "                    one_hot = [0] * 10\n",
        "                    one_hot[label] = 1\n",
        "                    t_train.append(one_hot)\n",
        "\n",
        "                else:\n",
        "                    t_train.append(label)\n",
        "\n",
        "    x = np.array(x_train)\n",
        "    t = np.array(t_train)\n",
        "\n",
        "    return (x, t)\n",
        "\n",
        "def load_custom_data(one_hot_label=False):\n",
        "    return read_file(train_data_path, one_hot_label), read_file(test_data_path, one_hot_label)\n",
        "\n",
        "load_custom_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx0UVnxyo3tX"
      },
      "source": [
        "### Use MINIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na81Nc7bvCN4",
        "outputId": "60a3f225-946e-4a26-b535-3d89f99a9c46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import sys, os\n",
        "sys.path.append('/content/')\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# dataset_dir = os.path.dirname(os.path.abspath(\"/content\"))\n",
        "dataset_dir = \"/content\"\n",
        "dataset_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(dataset_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"读入MNIST数据集\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 将图像的像素值正规化为0.0~1.0\n",
        "    one_hot_label : \n",
        "        one_hot_label为True的情况下，标签作为one-hot数组返回\n",
        "        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组\n",
        "    flatten : 是否将图像展开为一维数组\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (训练图像, 训练标签), (测试图像, 测试标签)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dataset_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(dataset_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_mnist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjRQLf1HjZZY"
      },
      "source": [
        "# Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4IRMbnVNRwY"
      },
      "source": [
        "## Basic Funtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnVM4bfSjk0t",
        "outputId": "1fa5b667-1a7e-4f5c-b22a-bf20b74c5beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0]\n",
            "[11  9]\n",
            "[13  8]\n"
          ]
        }
      ],
      "source": [
        "# Activation Function\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def step(x):\n",
        "    y = x > 0\n",
        "    return y.astype(int)\n",
        "\n",
        "print(step(np.array([1, 3, 0])))\n",
        "\n",
        "# Old and widely-used activation function.\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# There are three common places of these three activation function:\n",
        "#\n",
        "#  1. The output is between 0 to 1\n",
        "#  2. Both is liner function\n",
        "#  3. The more important the input is, the bigger the output is.\n",
        "\n",
        "x = np.array([1, 2])\n",
        "w = np.array([[3, 4], [5, 2]]) # The row number should equal to x's length.\n",
        "\n",
        "# Diffrent operation order will output diffrenet result\n",
        "print(np.dot(w, x)) # [11, 9]\n",
        "print(np.dot(x, w)) # [13, 8] [1 x 3 + 2 x 5, 1 x 4 + 2 x 4]\n",
        "\n",
        "# Central Difference Derivation\n",
        "# We use 2 h to reduce the deviation.\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4\n",
        "    return (f(x + h) - f(x - h)) / (2 * h)\n",
        "\n",
        "def func_1(x):\n",
        "    return 0.01 * x ** 2 + 0.1 * x\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = numerical_diff(func_1, x) # This is a valid operation (boardcast)\n",
        "\n",
        "try:\n",
        "    is_training\n",
        "except:\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a - c) # e ^ (a - c)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y\n",
        "\n",
        "def softmax_batch(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 溢出对策\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428IuPKjnPPa"
      },
      "source": [
        "## Cross Entropy Error\n",
        "\n",
        "We want the loss function result as small as possible.\n",
        "\n",
        "We introduce loss function to find a params that generate small loss function result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wEBMqCA-nRWg"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta))\n",
        "    \n",
        "def cross_entropy_error_batch(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    \n",
        "    # Only output the index of the right anwser.\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1) # 1 is the max\n",
        "    \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lnw14Dwl-hc"
      },
      "source": [
        "# Graident\n",
        "\n",
        "In vector calculus, the gradient of a scalar-valued differentiable function \n",
        "$ f $ of several variables is the vector field (or vector-valued function) f whose value at a point is the \"direction and rate of fastest increase\".\n",
        "\n",
        "The most basic way to find the gradient is to use the numerical differentiation method.\n",
        "\n",
        "$$  grad(x, y) = \\frac{f(x + h) - f(x - h)}{2h} $$\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 还原值\n",
        "        it.iternext()   \n",
        "\n",
        "def test_function(x):\n",
        "    return x[0] ** 2 + x[1] ** 2\n",
        "\n",
        "def gradient_desent(f, init_x, lr=0.01, step_num=100):\n",
        "    \"\"\"\n",
        "    lr is Learning Rate. This should not be too large or too small.\n",
        "    \"\"\"\n",
        "\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "\n",
        "    return x\n",
        "```\n",
        "\n",
        "There are four mainstream gradient desend algorithum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6gWqIjrNrdg"
      },
      "source": [
        "## SGD (Stochastic Gradient Descent)\n",
        "\n",
        "We can get new weights by:\n",
        "\n",
        "$$ W \\leftarrow W - \\eta \\frac{\\delta L}{\\delta W} $$\n",
        "\n",
        "$ \\eta $ is the learning rate, and $ \\frac{\\delta L}{\\delta W} $ is the gradinent of $ W $\n",
        "\n",
        "The SGD sucks when the function is not anisotropic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "fXadNma1P0XQ"
      },
      "outputs": [],
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        for key, val in params.items():\n",
        "            params[key] -= self.lr * grads[key]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmwLtamENzTh"
      },
      "source": [
        "## Momentum\n",
        "\n",
        "This method can make the gradient reach the extreme position faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "cSR-RnRXN2j_"
      },
      "outputs": [],
      "source": [
        "class Momentum:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, val in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "            params[key] += self.v[key]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvmXJIvTQFwR"
      },
      "source": [
        "## AdaGrad\n",
        "\n",
        "AdaGrad (Adaptive Gradient) is an algorithm for gradient-based optimization that adapts the learning rate component-wise to the parameters by incorporating knowledge of past observations. It introduces the **learning rate decay** method. Compared with the momentum method, this method will gradually reduce the learning rate.\n",
        "\n",
        "$$\\Delta w_t = - \\frac{\\eta}{\\sqrt{\\sum_{i=1}^{t} g_{i}^2 + \\epsilon}} g_t$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "zL6TPk60QiFL"
      },
      "outputs": [],
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, learning_rate=0.01, epsilon=1e-8):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.cache = {}\n",
        "\n",
        "    def update(self, params, gradients):\n",
        "        if not self.cache:\n",
        "            for key, value in params.items():\n",
        "                self.cache[key] = np.zeros_like(value)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.cache[key] += gradients[key] * gradients[key]\n",
        "            params[key] -= (self.learning_rate * gradients[key] / (np.sqrt(self.cache[key]) + self.epsilon))\n",
        "\n",
        "        return params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sOU-gn9YqEA"
      },
      "source": [
        "## Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "81T5whX0YrnH"
      },
      "outputs": [],
      "source": [
        "class Adam:\n",
        "    def __init__():\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZJkBsNk8NQ"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O3UbAWBlY5f"
      },
      "source": [
        "## Relu\n",
        "\n",
        "Return x if x is larger than 0, otherwise return 0.\n",
        "\n",
        "$$\n",
        "Relu(x) = \\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        1 & \\mbox{if } \\ x > 0 \\\\\n",
        "        0 & \\mbox{otherwise }\n",
        "    \\end{array}\n",
        "\\right.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "EWaHBc_BlFmK"
      },
      "outputs": [],
      "source": [
        "class Relu:\n",
        "    def __init__(self) -> None:\n",
        "        self.mask = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x should be a numpy array here\n",
        "        \"\"\"\n",
        "        self.mask = (x <= 0) # An array represting wheather each element is larger than 0. [True, False, False]\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        \"\"\"\n",
        "        Set all the `Ture` in mask to 0\n",
        "        \"\"\"\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sas1Bu3nlPqI"
      },
      "source": [
        "## Affine\n",
        "\n",
        "$$\n",
        "Affine(x) = X • W + b\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "3_yAy2vhlR8T"
      },
      "outputs": [],
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b) -> None:\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        dot = np.dot(self.x, self.W)\n",
        "        out = dot + self.b # Boardcasting...\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdcMMpfamwXf"
      },
      "source": [
        "## SoftmaxWithLoss\n",
        "\n",
        "The Softmax Loss is a widely used loss function in the field of deep learning. It is also referred to as the Cross-entropy loss with softmax.\n",
        "\n",
        "Let us consider the training data, denoted as 't', which is assumed to have undergone one-shot training, represented as follows:\n",
        "\n",
        " $$ t = (0, 0, 0, ..., 1, 0) $$\n",
        "\n",
        "Here, $ t_{k} $ corresponds to the correct answer. The predicted result, denoted by $ z $, can be expressed as:\n",
        "\n",
        " $$ z = (z_{1}, z_{2}, ..., z_{C}) $$\n",
        "\n",
        "The corresponding loss function, 'lz', can be formulated as:\n",
        "\n",
        " $$ l_{z} = \\sum_{i=1}^{C} t_{i} log(z) = -log(z_{k})$$\n",
        "\n",
        "In comparison to a linear function, the logarithmic function better represents our desired objective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "3tKcHjDbmyIJ"
      },
      "outputs": [],
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self, print_result=False) -> None:\n",
        "        self.loss = None\n",
        "        self.print_result = print_result\n",
        "        self.y = None\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t \n",
        "        # Teaching Data. Marking the right answer.\n",
        "        # Set right anwser to 1 and wrongs to 0. For exmaple, [0, 0, 0, 1, 0, 0]\n",
        "\n",
        "        self.y = softmax_batch(x)\n",
        "        self.loss = cross_entropy_error_batch(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVQCcg1HWvr"
      },
      "source": [
        "## Batch Normalization\n",
        "\n",
        " $$ l_{B} \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m} x_{i} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "X9qF09xwHaU8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout\n",
        "\n",
        "Dropout layer will randomly delete some points. Since the network differs every time, it's similar with intergrate-learning(Use multiple models to learn and get the average)."
      ],
      "metadata": {
        "id": "wl7kCVngnOUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "    \n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            # Replace the item large than ratio. [True, True, False, ..., True]\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "        \n",
        "    def backward(self, dout):\n",
        "        # Same with Relu\n",
        "        return dout * self.mask\n"
      ],
      "metadata": {
        "id": "Chbap8VQnXK-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F104OfzFpsmz"
      },
      "source": [
        "## Convolution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CIvPQLzHpuSo"
      },
      "outputs": [],
      "source": [
        "class Convolution:\n",
        "    def __init__(self, W):\n",
        "        self.W = W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-0ClQiqp3JO"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBySGUTJjy39"
      },
      "source": [
        "# Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVl0mOKYmKFr"
      },
      "source": [
        "## Multi-layer Net\n",
        "\n",
        "This network reach a accuarcy of 97%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "HUem1Q5Dj09y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01, initParams=None, weight_decay_lambda=0, use_dropout=False, dropout_ratio=0) -> None:\n",
        "        \n",
        "        self.params = {}\n",
        "        self.weight_decay_lambda = weight_decay_lambda\n",
        "\n",
        "        if initParams is not None:\n",
        "            self.params = initParams\n",
        "        else:\n",
        "            # Select {hidden_size} numbers from 0 - 0.01 * input_size\n",
        "            self.params[\"W1\"] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
        "            self.params[\"b1\"] = np.zeros(hidden_size)\n",
        "            self.params[\"W2\"] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
        "            self.params[\"b2\"] = np.zeros(output_size)\n",
        "\n",
        "        self.layers = OrderedDict() # Remember the order of the addition\n",
        "        self.layers['Affine1'] = Affine(self.params[\"W1\"], self.params[\"b1\"])\n",
        "        self.layers['Relu1'] = Relu()\n",
        "\n",
        "        if use_dropout:\n",
        "            self.layers['Dropout'] = Dropout(dropout_ratio)\n",
        "\n",
        "        self.layers['Affine2'] = Affine(self.params[\"W2\"], self.params[\"b2\"])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss(print_result = (not initParams == None))\n",
        "\n",
        "    def predict(self, x, train_flg=False):\n",
        "        for key, layer in self.layers.items():\n",
        "            if \"Dropout\" in key or \"BatchNorm\" in key:\n",
        "                x = layer.forward(x, train_flg)\n",
        "            else:\n",
        "                x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x, train_flg=True)\n",
        "\n",
        "        return self.lastLayer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x, train_flg=False)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        \n",
        "        # Get the index of the maximum value. If one-shot is enabled the max value is 1\n",
        "        # For example, [[1, 0, 0], [0,0,1]] will be converted to [0, 2]\n",
        "        if t.ndim != 1: t = np.argmax(t, axis=1)\n",
        "\n",
        "        # if x.shape[0] <= 50:\n",
        "        #     print(\"Expected Anwser: \" + str(t))\n",
        "        #     print(\"Exact Anwser: \" + str(y))\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "\n",
        "        return accuracy\n",
        "    \n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "    \n",
        "    def gradient(self, x, t):\n",
        "        self.loss(x, t)\n",
        "\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "        \n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        grads = {}\n",
        "        grads[\"W1\"] = self.layers[\"Affine1\"].dW + self.weight_decay_lambda * self.layers['Affine1'].W\n",
        "        grads[\"b1\"] = self.layers[\"Affine1\"].db\n",
        "        grads[\"W2\"] = self.layers[\"Affine2\"].dW + self.weight_decay_lambda * self.layers['Affine2'].W\n",
        "        grads[\"b2\"] = self.layers[\"Affine2\"].db\n",
        "\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ikKQHFmTLT"
      },
      "source": [
        "## CNN\n",
        "\n",
        "Convolutional neural networks is an enhanced version, which offers significant advantages, most notably the preservation of data shape. In previous neural network architectures, it was often necessary to convert two-dimensional arrays to one-dimensional arrays. \n",
        "\n",
        "With CNN, however, original-shaped data can be directly inputted into the network, without the need for additional preprocessing steps. As a result, CNNs outperform other neural network architectures, particularly when processing colored images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGTcZ_vTsQnY"
      },
      "source": [
        "# Training\n",
        "\n",
        "It's unusual for the accuracy to plateau after only a few epochs, especially if you're using a relatively large dataset.\n",
        "\n",
        "## Optimization\n",
        "\n",
        "* Use Dropout\n",
        "* Use weight decay\n",
        "* Enlarge the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "b58Yf86LP0q4"
      },
      "outputs": [],
      "source": [
        "#@title Training Config { run: \"auto\" }\n",
        "\n",
        "scene = \"Production\" #@param [\"Train\", \"Production\"]\n",
        "network_type = \"MultiLayer\" #@param [\"MultiLayer\", \"CNN\"]\n",
        "learning_rate = 0.01 #@param {type:\"number\"}\n",
        "batch_size =100 #@param {type:\"number\"}\n",
        "iters_num = 30000 #@param {type:\"slider\", min:5000, max:100000, step:5000}\n",
        "optimizer_type = \"Momentum\" #@param [\"SGD\", \"Momentum\", \"AdaGrad\", \"Adam\"]\n",
        "train_data_source = \"MINIST + Custom\" #@param [\"MINIST\", \"MINIST + Custom\"]\n",
        "test_data_source = \"Custom\" #@param [\"MINIST\", \"Custom\", \"MINIST + Custom\"]\n",
        "weight_decay_lambda = 0 #@param {type:\"slider\", min:0, max:0.3, step:0.01}\n",
        "use_dropout = True #@param {type:\"boolean\"}\n",
        "dropout_ratio = 0.15 #@param {type:\"slider\", min:0, max:0.3, step:0.01}\n",
        "load_params = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pHkHWIfEssBH",
        "outputId": "57823e10-fba0-4619-b346-6e35b0ff4f68"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748070>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAM0lEQVR4nGNgGFjwH12ACY8csiQmIF8Sn3uINRZTI+1di89OLHLUsBOfsdjkqBMrgwMAAAD9CBdExnYLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYklEQVR4nM1QQQ7AMAhSs/9/mR2WdCpodhwnK4JYs48AWsNfqr2rjsXRjbr1vpjtH1wTkdPBHLWTS4gzgqZ0Ds4ZhxPaYtulcYTbRjUSPKiFq3I8RSKlBV3qyXH6W1fc/3AD5oscDdz+CcwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUklEQVR4nGNgIBcwQun/SGxs4P9/fKYQkEXjM+GTRZXEq5MUSRIchEcSw5tE24lPJ0mBh6yTRI0InRA51FhjgbMYMVMDcjLBSCeMcDl8KWiwAABryxQNfbH6mgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAT0lEQVR4nGNgIBcwovH/YxOESv1HkBhyaDR2A6A0Ex453BaTLodsKDY78Uni98hAyTIwMJDuFUKS/4nQiS1F/IcJY0r+RwhiMxZ7+qITAAAO4xr9MdIWfwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXElEQVR4nMWSOw7AMAhDMfe/M91SbKjVpaqnxC98FIgwQjuXGiAi73EQiqJENZw0rMUtMKf1quIduVa0af+AR9snWNoGUaFjoevEIbgpDdMd4qxpGC3YaAbP6DNdFwYWEWZyCpsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASklEQVR4nL2QSw4AQATFau5/Z7P1CWHDTqovgPsSBaSCgNomQsxAFQKg2kAcfA1rxWAuRG9GMSw0T3VmWmcc25n5yGns0pw/4ag+kiYQCzvgvtoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAV0lEQVR4nM2QQQqAQAwDJ+L/vxwPiyiYhj0a6GmYbrrwmxiAo7AqZnNHjOaWOLSdoRus2TTPKBrEmrxVAxRgNL+pXOhZlkw1WM27V/nb7x0A9prMPXrvXEr9FRY4bNf9AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYklEQVR4nJ2ROxIAMQhCyd7/zqTYQuJvTCxlHooCTa3QoXW/RFtgYUUAIFOSOsyLh2WYqRsGEYJGUYwT0uB4hD9pQZqWXEi8bqO01eXszjd1TZ89AotnD0BPnuBFFL6SDsQGlaYaF/M+Ay4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAVklEQVR4nM2QQQoAIAgEV///ZztIGboFQQc9RaPbJNCgbDsrAJhR5hDCUzT3S4E81aGky4MjmcQUTgG6NEhyyFl0SYExe/g1f5OyvIRf8ObzEnvdf4ManU8UEPkwVeIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAALklEQVR4nGNgoAv4j8xhwieLIYlX56CWRAf4A4Fcyf/4JIl3D31C6D8OVUMCAAC1VwYbsVemZQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAS0lEQVR4nGNgGOTgPzKHCY8cuiTxpqLp/M/AwPD/Pw5JNIAmyYhbEtVGkoyFmgpzE7Il/9FVsWAxjRGLGKZ+UvyJ6h3SdFJHciAAAOj7DBrXBPJnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAARUlEQVR4nNWQQQoAIAgEx+j/X7ZbBcpmt/IkDOMuwivjDkCPYK0tYQaWm7btwTz3EeasdH22ZibQFaxF3maqx2uzCv+aAQm4ChpTFDF7AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nO2QQQoAIBACp/7/ZzsEtUFtec+TICoKHxRAgR8geVp96XZDL1oF0JyzoG9T4H7vJjrdGUQvNTgzo/3ROCF7YIsG0wQY+BvU3KgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQUlEQVR4nGNgGI7g/390ESZ8yhmRdGKIMWHKIQALdlMw7cRwEbLq/+gC6Eb9x2I6dsPhyqBaUHQiWP9xOHkU4AEAMTUNCv3JOAQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAP0lEQVR4nGNgoAlgROP/RxZiRJfCpgNZxX98VsElmfDIYZPEayg+K4mVQ7cTRR/WQMAiw8DwH+EYvAExCmgMAK2GD/1Bw0J1AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAATklEQVR4nOWQMQ4AIAgDi///cx3UICmwOtjBGA8PFPg19O1oGCyHcrwhz5Jo7wi0DgIEd4lCCwPnM5Xauicb8XpnddNcnWljncLib19nAu43FQciq6fwAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXElEQVR4nK2QQQ7AIAgEl8b/f3l7KAIJVFvaPWjMZBYV6EZ0JyAA7RxD+uo51KsMhTW7IOdcKeBd9lAQykszM4eEpDsP0+rXmJuK+0+Jte/Mh3D1CR9ql/l1Zj8ntqkSIQz5mQoAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748250>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUUlEQVR4nOWQwQoAIAhDp/T/v2yXJkRjQdd2EudzIvCXSjXTeDTt0ndSt9N4FvSZ6baSlAMBoKJY7hocUWgfFMK+XruYM7NJlRltnCAx+12tCZPqEhEf/9cMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQklEQVR4nGNgGGSAEVPoP1ycCasORogKrJIwgE2SEbckwkpcxv7HJYnwABZJAl6Bmopd8j9OBzHC9GEHeCVHAdEAAK3rCRbekHq2AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748340>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAK0lEQVR4nGNgGAXI4P9/dBEmYnViiODViZDE1EisThLdg9CJRY4qdg5vAABbfAYLYa58JwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787480A0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASElEQVR4nO2QMQ4AIAgDi/H/X64DBhOLbGx27HEhKfDTH2o1qvvx1ALmDObMNjcxD1OTMKrlzQZUhpkqV5g9LUcIMyvLhZqyAKrYDw0XmhDQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAQ0lEQVR4nGNgGAXDCTBiE/wPFWfCLocT/P8PwQwMLETahGkyNjvhtmKXxGMBzCdYJOEeYUR37X+Yjv/YdP4nwisQAADE5g0MwINPzAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAARUlEQVR4nO2PMQ4AMAgCpf//M13s0goxzmWEiEfEVKhMpr/KDEHXSJdS1Z5MhY2P75QkgaoFGlss0IA2eS2tuJs8+7q0AUULEQakRUNMAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678580CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nO2QsQ0AIAzDUsT/L5cBAUtq9QAy1nIUVfopk5I0gKHIrKhtlDqzt8aYT4wKGnBY0odozRbZnF4OPyrt9VJ8UDMLWtQTA5J9E0sAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678580CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXklEQVR4nN2QsRLAIAhDA9f//+U4WAWNOHYoE+ZdSE7gN2Nz4/JaIAEDN/oMtpkS5AkBnnax++hSne6UFNmCqi9lqvPVi7sIWaBfavZMKzLzJ4g/4K3sqWvEFaW+ngZlaRwLxx9ocAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678580CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASUlEQVR4nGNgGEqAEUPkP0KUCV3qP5J6FnRdjEjGsWBK/cdq/38UCrsSvJIIJrpr8RqKIonhT2I1ouskXiOma3FL4jWVgOzgBgCkSRMIMZnwCAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678580CA0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUklEQVR4nNWQQRLAIAwCwen/v0yPCmkcj5abIeAq8F9JdnzqAsDGtGiaRKe4ctMZNcoJzSOgZTTCA5fySdtzfhOPfs0zGbSknLW+c/N9hwB36gXRPhUP5yafhgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUklEQVR4nM2SMQ4AIAgDwfj/L+PgIK1Jhc1OyFklWjMhT3XQmhWhTnrQVA9FbyidVdgcSMBQsHwlO8uPx86GEZ2bnV+bsNUxDRwTaDgwlaDvtQBhgRQNE79d6QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAYklEQVR4nM1QQQ7AMAhSs/9/mR2WdCpodhwnK4JYs48AWsNfqr2rjsXRjbr1vpjtH1wTkdPBHLWTS4gzgqZ0Ds4ZhxPaYtulcYTbRjUSPKiFq3I8RSKlBV3qyXH6W1fc/3AD5oscDdz+CcwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUklEQVR4nOWQMRLAMAjDRP7/Z3fqpW5NhmQsI0LgA5oSMKwhYw4ptx3K5xy+pgzWU+2MaHIHVgpEfUKlzQUKcLqJtTddbZ5wCld5dtYu//+zugATABQPFZQHwgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXklEQVR4nJ2RQQ4AIQgDB///Z/Zm0qIEl5uZTA0lkEkg9ms5C5LzJEBuugq7xXqk/hk0EFUNarCbIkcltxKUeUMa9LRKO92eXX0PqfXYU/F07JkoZhGnq+Rfs4q9+QHYWxoZWyw/LQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASklEQVR4nGNgGEqAEZnzH0MEIfUfQWLIodHYDUAwmfDI4bCYdDk0QzHsxCeJ3yMDJQtjkOQVQpL/8UkiAEai+I8kxohbCouxyKoBJLoa/adNSL0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAWUlEQVR4nL2QQQoAIQwDE9n/fzl7qMLCpqEnC+phnDYKXCzVsQKLojVHojNnok/bQyUYa2o+ThRAYG+uKxtIAAL7mfSBPr2MyQSjeXKFv/09o6Bq+QtqvXm9w3AVFiUr5YgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66787481C0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASklEQVR4nGNgGBmAEUr/R2JjSELlUcXQVP/HLoyq5j8eSagJTHjk8GrErpMYjVh1wjVidxARpmLTiXAOqcbi04nkSRKNJVYnXkkA3YEQC8z3xygAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXklEQVR4nMWSOw7AMAhDDfe/s7ukKCDH6hLVE/DCRwHAKMpidzeP4vWyCQRHVhNFLA2rPAlTBT90fDMPHW3ZP+CS/gRLaxWcy0QLKIyGm9KwfkOzahq2HZgYJs7omh5C7hYR48WtgAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748A00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAL0lEQVR4nGNgGNbgP4zBhE8WqyRenYNWEhvAHwh4JP/jkyTfQdQwlkTJ/1hUkQwA9l0GGwZKkvwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1BE0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAFklEQVR4nGNgGFzgP9NAu2AUjALsAACh5AECYu2K4QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748A00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAS0lEQVR4nOWPORIAIAjEguP/v4yFR+OCNlZuSSYLwJOYHjtgFIm8S1Va1js3OJCH20K4tiYQQF+blk6o/7wQpXklBtfGMG090N/SAL1KEwicha77AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B15B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAPElEQVR4nGNgwAMYkTn/0fiMKFIYylHB///47EGWZMIjhyGJ11B8VpIgx4RHDksgoAtD3fIfm7JRMKQAAHyzD/36yWEAAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748A00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAXklEQVR4nOWQORLAMAgDBZP/f1lpEiMOu0sVKsPOgsbAJ2XxZG61I2BgptdiWVLIAQGuTdV9ZdmsfihZpya0eXqzme983husq36K6RKrbU2fUH2Bp7BDVgtrDvWHugH+tRwLMKVjpwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1520>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAR0lEQVR4nO2QMQ4AIAwCqfH/X8bBaBdKGmcZezlCCvy8hQAwDLOiZ0Vto1SZvTXCTDEqKMBhdB9ya7bozanl0KMor5faB2UWM3wTA7Q8musAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F6678748A00>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAUElEQVR4nNWQwQ4AMARDS/z/L9thE8tSnOeoWg/gv3KnbcsBQAqRWkN8TePKJvPEeRUsgelE1ThBSLg1nBcUodLJUxmhW2WseWfzvmHxH7UAePUVD5rD42QAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7F66846B1610>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAASElEQVR4nOWPQQoAIAgE1+j/X94ukVBqWcf2ojDsiMDHYZ8lYCY8slpNAiC3WguKD6lrVtutpPoNq1RPubTmfvrPcfii+QzDNJBoDBpJye3PAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[42m● Entering Production Mode...\u001b[49m\n",
            "Results: \u001b[33m[7 5 7 7 4 2 7 6]\u001b[39m\n",
            "Expects: \u001b[32m[1 3 7 2 8 6 5 4]\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from colorama import Fore, Back, Style\n",
        "import math\n",
        "\n",
        "def train(x_train, t_train, x_test, t_test, initParams=None):\n",
        "\n",
        "    network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10, initParams=initParams, weight_decay_lambda=weight_decay_lambda, use_dropout=use_dropout, dropout_ratio=dropout_ratio)\n",
        "\n",
        "    optimizer = None\n",
        "\n",
        "    if optimizer_type == \"SGD\":\n",
        "        optimizer = SGD(lr=learning_rate)\n",
        "    elif optimizer_type == \"Momentum\":\n",
        "        optimizer = Momentum(lr=learning_rate)\n",
        "    elif optimizer_type == \"AdaGard\":\n",
        "        optimizer = SGD()\n",
        "    else:\n",
        "        optimizer = SGD()\n",
        "\n",
        "    train_size = x_train.shape[0] # 60000\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "    for i in range(iters_num):\n",
        "        batch_mask = np.random.choice(train_size, batch_size) # Select a batch_size between 0 - train_size\n",
        "\n",
        "        # Randomly select a part of data\n",
        "        x_batch = x_train[batch_mask]\n",
        "        t_batch = t_train[batch_mask]\n",
        "\n",
        "        if not initParams:\n",
        "            grads = network.gradient(x_batch, t_batch)\n",
        "            optimizer.update(network.params, grads)\n",
        "\n",
        "        loss = network.loss(x_batch, t_batch)\n",
        "        train_loss_list.append(loss)\n",
        "\n",
        "        # Only calcuate accuracy every epoch. All data passed in.\n",
        "        if i % math.floor(iter_per_epoch) == 0:\n",
        "            train_acc = network.accuracy(x_train, t_train)\n",
        "            test_acc = network.accuracy(x_test, t_test)\n",
        "            train_acc_list.append(train_acc)\n",
        "            test_acc_list.append(test_acc)\n",
        "            # print(train_acc, test_acc)\n",
        "    \n",
        "    epochs = range(len(train_acc_list))\n",
        "    print(epochs)\n",
        "    plt.plot(epochs, train_acc_list, label='Train Accuracy')\n",
        "    plt.plot(epochs, test_acc_list, label='Test Accuracy')\n",
        "    plt.title('Accuracy Change Per Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return network.params\n",
        "\n",
        "param_cache = None\n",
        "param_cache_dir = \"/content\"\n",
        "param_cache_file = param_cache_dir + \"/params.pkl\"\n",
        "\n",
        "if os.path.exists(param_cache_file):\n",
        "    with open(param_cache_file, 'rb') as f:\n",
        "        param_cache = pickle.load(f)\n",
        "\n",
        "minist_dataset = load_mnist(normalize=True, one_hot_label=True)\n",
        "custom_dataset = load_custom_data(one_hot_label=True)\n",
        "\n",
        "if train_data_source == \"MINIST\":\n",
        "    (x_train, t_train), _ = minist_dataset\n",
        "elif train_data_source == \"MINIST + Custom\":\n",
        "    (x_train_mnist, t_train_mnist), _ = minist_dataset\n",
        "    (x_train_custom, t_train_custom), _ = custom_dataset\n",
        "    x_train = np.concatenate((x_train_mnist, x_train_custom), axis=0)\n",
        "    t_train = np.concatenate((t_train_mnist, t_train_custom), axis=0)\n",
        "\n",
        "if test_data_source == \"MINIST\":\n",
        "    _, (x_test, t_test) = minist_dataset\n",
        "elif test_data_source == \"MINIST + Custom\":\n",
        "    _, (x_test_mnist, t_test_mnist) = minist_dataset\n",
        "    _, (x_test_custom, t_test_custom) = custom_dataset\n",
        "    x_test = np.concatenate((x_test_mnist, x_test_custom), axis=0)\n",
        "    t_test = np.concatenate((t_test_mnist, t_test_custom), axis=0)\n",
        "elif test_data_source == \"Custom\":\n",
        "    _ , (x_test, t_test) = custom_dataset\n",
        "\n",
        "print(Back.GREEN + \"● Entering \" + scene +  \" Mode...\" + Back.RESET)\n",
        "\n",
        "if scene == \"Train\":\n",
        "    initParams = None\n",
        "\n",
        "    if load_params and param_cache:\n",
        "        initParams = param_cache\n",
        "    \n",
        "    print(\"x_train size: \" + Fore.CYAN + str(x_train.shape) + Fore.RESET)\n",
        "    print(\"x_test size: \" + Fore.CYAN + str(x_test.shape) + Fore.RESET)\n",
        "    \n",
        "    params = train(x_train, t_train, x_test, t_test, initParams)\n",
        "\n",
        "    if not load_params or not os.path.exists(param_cache_file):\n",
        "        with open(param_cache_file, 'wb') as f:\n",
        "            pickle.dump(params, f, -1)\n",
        "            \n",
        "elif param_cache:\n",
        "    network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10, initParams=param_cache, weight_decay_lambda=weight_decay_lambda)\n",
        "\n",
        "    print(\"Results: \" + Fore.YELLOW + str(np.argmax(network.predict(x_test), axis=1)) + Fore.RESET)\n",
        "    print(\"Expects: \" + Fore.GREEN + str(np.argmax(t_test, axis=1)))\n",
        "    \n",
        "else:\n",
        "    print(\"Please train params first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFggngb-Zdlh"
      },
      "source": [
        "## Reference\n",
        "\n",
        "1. Saito Yasuhiro. Deep Learning from Scratch[M]. Japan: O'Reilly Japan, 2016.\n",
        "\n",
        "2. 管他叫大靖. (2021年05月24日). Softmax Loss 的推导及改进. 知乎专栏. (https://zhuanlan.zhihu.com/p/374018199).\n",
        "\n",
        "3. Khelifi Ahmed Aziz. Medium. Learn How to Write Markdown & LaTeX in The Jupyter Notebook (https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd)\n",
        "\n",
        "3. Jay Gupta. Medium. Going beyond 99% — MNIST Handwritten Digits Recognition (https://towardsdatascience.com/going-beyond-99-mnist-handwritten-digits-recognition-cfff96337392)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "RjRQLf1HjZZY",
        "428IuPKjnPPa",
        "V4ikKQHFmTLT"
      ],
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "18B-Fujnr7uDhfyERZzWHTI3-31anw5OH",
      "authorship_tag": "ABX9TyM4miUSAuvwebyPdLjL8biZ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}