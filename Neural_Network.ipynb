{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiverTwilight/Neural_Network/blob/master/Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EzQhFI_imOU"
      },
      "source": [
        "# Overview\n",
        "\n",
        "> Created by **Rene Wang**\n",
        "\n",
        "This is a full example of how to detect hand-writting number with deep learning. The example is based on the MNIST dataset, which contains 60,000 training images and 10,000 testing images. Each image is a 28x28 grayscale image of a hand-written digit. The goal is to train a model to correctly classify the digit in the image.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/drive/18B-Fujnr7uDhfyERZzWHTI3-31anw5OH?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "<a href=\"https://ibb.co/zXNKG13\"><img src=\"https://i.ibb.co/3pktBwx/0f63c745a964ec5cd2e85cda9cb656a.jpg\" alt=\"0f63c745a964ec5cd2e85cda9cb656a\" border=\"0\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "RwXl6HSPOKEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc39b5e-2a2b-45a0-96f0-a29d90eb85b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.9/dist-packages (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install colorama\n",
        "is_training = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdTZJ42evAVC"
      },
      "source": [
        "## Dataset Process\n",
        "\n",
        "This will transform the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). You can use this [script]() to generate augumented dataset with applying little translate and rotataion to the exsited data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Mc8rwDOo2Ts"
      },
      "source": [
        "### Use Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "-t2zz9-LQUTq"
      },
      "outputs": [],
      "source": [
        "#@title Custom Data Config\n",
        "min_therehold = 127 #@param {type:\"number\"}\n",
        "max_therehold = 255 #@param {type:\"number\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "id": "tYhjEh7dZmQz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47ee4ad6-aff4-4f21-bb3e-60281a394ea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362EB0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAB3ElEQVR4nOVYSZLDIAyUpvL/L/ccbMcQtLSQD1OTvqQiGi1IgLDIF0NJHmgmD1QcKGsmFHO24XIZM2aQKLpQAUT0uWxBRARwBh35NPxBApDNayB0N5oTjGxFj4/fyBxQXRCTfiqxVY1SHcV5/doMEBW2cGxlb9+oonUcOsS3xYE2zfhhbKQO5flaGI7fqnrIuSKwPVqkjuMvwsKB1g4tHT8nFWlBBftUvb/jAJN54MrD7gFqxZ7qatxV6q3LLB4z76pC+95YphN1lFKSW2aw7hQRteefSNIGWmahw6hd9UPwwTrCLSMWG9M7FrEszNltzEJqzydJyN3cWrzHjrtDl0Gny76X+nr0HXvGsqm+L8/7DiWCZxJLUJ5vZmsnzXEGwD68XeeiZvHQRxlfuvuEniusj3l7vpEYLgP6+Te0yMXutYFc7ETZZ33W7qpp+1kHNMyL8O1tYGP3kleJmidGq4rXBHM+3ZnfjCF+7S7ECera5PMZPg0TXMFHLY6EDxP1TlACrboPTPo9/4S87BXRpyqkLdDFM/v7dtU7tjgQe14DJ7nIbRo5dwP+bppHruAjNzbqKyc+FTrzecxzgv+Y0UE5dKqclKb+PwDmLVPoHkrf8P4W4j7hK1FpG38Be/m69/6DAe0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362490>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABnUlEQVR4nO1Yy47DMAhkVv3/X549pFEbGwjj2G2k3blESjAMD2Mcs3/8TeDbBCaCZjDjuE+cyeYiSInNJq2s+elUKPZ8+3NAagoHMv5Q6KTaZ9cMVKV6tXeZj5ET2Tbc7BZS18f9IVBQMp9Cd7vCc20LEjJ/s5NBi4srXc887TxZr6/s3sSMYpnEXusN6L2NpDdMK/vGAhKbvXSILHbsv4u7RHB++q4+VZgfLzDjUYIGf0lApHM+slcJqhies00k5pEygZll3yJ3DsaULy3tHOg2/b7IN+ah7jx2TtXaOD3KYGaMpN7iElQ/UT3UiyEJ1b2tj51vN2CR2eAR6jS8QFnUO9Syzwv5QCPvV8/M6hv1Zc7zVFLWOh8tfh5ddd1g7hm4VdP45FTuh6HgvIbnN6A4XFfnRRoS7Z20J6mMtwOT9rqJmIZee0AQpHs5lpy/FZQrL+Bm4ej89EvUwluZqBrOgkcjMQ5/7bK6B72jTsPKCW/tddz1OxqH/G+S82qcL/xInQ4vDyvZfd73aBA28+8H64jc6NfPnUrwLvgFPv95Oazdp78AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABnUlEQVR4nO1Y27LDIAhczvT/f3n7ENMGFEVjYmZOeWgz3mABAQF+9D9JVgsAAFwkx98KpoYIAVcLsZK4Av0rHyKwwA1X+H0BPCAg7xVmst2JsjapR4vgH00eMLVCfG0eomsJ/P0eyDBPNv0ygXNWKKXk4LcrTzt4mUY2TlU437mmHAm6a/iI298bewU1Yx5kCUQiUX/2pNZ+AnnmuV4Zfq6j/WynRWeFHS0UOZ2p7mq9KKfffsP2NyeBVGopV3gW0EPqLwFC2F27i6hasgi+K/jOIZeluuZChmQr5/iUBb4y5wFPOirNGdjTGZHUlIZCUSujoD3zzQ5IEiDNRfIOrS2qliSGYTveVefZcPtMRx72jtdYfV0kzWG/G2OGL9GJ8papFIr4E4ffC4dqNhqKatFDnTEOnglSSKDB+pC6WpOd8fBpWn8h8I7ovYhmVcjNZ42zjbM7RvHUMNCuMMVmsL6LRs9ntLGiJGTk4vvzdub0ez6ePoc8Tu2b7bgnjwoG4I+/9bG7uqF2Q+OCO6N+s13YRgDu6dqsasv/qEZvs1Cb/z9R1uAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F66783628B0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAB2UlEQVR4nL1Y2bbDIAh07un///LclyRVGRZjUh56UmFYlAAR7WEizEprzSz+jHrLkSeMfOyYVo6tIUQ/SGxtDgGzhPSESrZjo5M0AcLX+yjxeopskXLVZ00cI3PwXGxKRSRJ6eHf9D8IHgVbVqKCWtOoCYD0fg5Qa8Tx61gLg9jNzTpeOmEDvGMLoUiQ2vTzPsEqUWX8s4DPtUsZ0LaODqKZX3TNO5cqAbKBiTVQNMBBhV3CiVzBRa1Mrtu2LMRY2cirlZhUieHxxmhv2mlrWJaKSika7/Jljk3ucBJfxYHJ0Nm37iSwfOl1h5GCq+BYcVqCqJ87qlTR8k7pGhMjtopIAWwCVBi3QO5T4mLCLjg1BahzbJfem0NzzZVRDSVNLq31gZkZjQIDxxmnxgB3D2t5G7JJlWdlLtjTuqYTVG1nO8EiBVmEAFyReRmqkg4BHl8291/EG8jC10Z5hyFCHE8Qjdyo3KgNSzO7mIIVtvWgn2SoOx7V+FWm/OijOWlxvhWLn4Enayj3bo1+ed8kQugCdIf0WzPf1+Q2eTrU/V2Yoh69fAbRpHpeJVRg+hzqH7y3aG/WBImqCi/NXj+dzED+MeWwi/353RNM48te7/39X7p0eoPeLrL/E/yqHij5g/wAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_0_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F66783622E0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAB60lEQVR4nOVZS3bDMAiEvt7/ytNFXNfip0Gyk0VnkxcZBpAIIEfkH0P9EuI1JOI10Fd5H7xrQZAoxEtgRan2ZSq/tdkQCOBWcf3oONPVsTa7Jlet5RYXKZd2bFS+5h2nxst/2QWNcmd1N/VCWSOQWMzfSs1Y+fbKoaeOEkNQtaMxZeEV9SgqzJMH5rsPPoSnUwGOqFSQ2mOzJtUf28Xl285v+0AQvLpIYjsqp8/x0eJcn2VwHohtlbc2ziB45HmTIdkdcF2+lLLVR7MnC3AFT0RExzQmQogFnpxviqzPzZonPniIQO85ejB13vtUMJOEJFzw0JUTCzXAMZXh2GjnWV/VD4Ogz/eR2dPSFw7urI8pbJNWRJLf/Mw+B1ppMiSMRDol5o+PCX6n3t1Q82z0KihuGp1zigpeMNGUlHspONe2/rzKMZJGyrdNdsIrW7+GAx4/LEDJ0vhnMWVvzclB2sfbWV6WNodbsIIEbWcT7clnA829DdaRS3U9aFg+agG5BXSr69+7QLkBPS++d0DTWhBYMCdfxNEoJK9FkC+VJiKdeoBCOgjNpn2kufbqUtplLELGsTNSnhiDjw5+zujvwMd6x5Gc/RHRAFtv/7ZMvvM15dsoWaOfsMyNt49i0ueeNv2LT/27ckdhXMIP+zOzFAwFlHMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_0_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362940>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAB80lEQVR4nOVZS3bDMAiEvt7/ytOFnUYWw0+ym0XZ5FmCYRBYworIPxatKqKu2hN0WNwrRbfoKLcEInrvwkLEUqVLXA1eZTX5lMstyI47D9COfTVw9SyADhXg/PUUTuRgsjp8zKl6gHX6XM+NwQEBUpNjHtNz5K1EgurMg98NWxHFqDEsJU+dmwQOGUE1xauZK7hX9oQCMK65quDE0qCgClmC+/j0IcAzb/i88jPS0fezSd9gmTFQgOu0N5iWWxG37K+2igRtg+ds767FoJID1mqGlr2JJU/fFotzi54t7q/6CZEFf+FyjiTJXTiUBp3J3XwA9DGLpVg65y2/WdaTZItc918jniszRoIndsqHA4uykGVTzZujFLViWcn8bh76crx3yPbZCIHRLoAZI/DhwOJ3YrkZ23znmaIl0+ntq15usd6O3YpJvA0e8v4eOQbyc9djtPAp9JgQJiZ4OMUaRhEc83n0D16SJH5Yh5fs7S25vzlcXKvXxjWaux82Y90bK4brAWWnjoe73fDr/GhOD5t5+42J7JotTkZY+o/tCdNOBdapkbK3LVfe4cU8okkXON1nOy6LEWD6XXF1nYyqfrWDy6SG63zS9soxWtTNqlmUmkvvGsu9nuhJEvpjfwasinfQr0DVbi8/Jux6+88K9dOJ/wFQjsLyh7khdwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_0_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362550>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAB50lEQVR4nO1YSZLDMAiEqfz/yz0HxbEsFrE45TkMhxzE0ixCEDM9TCDip7DvAUbZFIjxWPQ34KJhDMTvn7yqUELWhatwwQ1Qp3YjAhnHHpXVWBueAADEUcSVkHkN0dU37eKirliMWZsTBSYld9BEF4lIunWpcTqVfhLb21WujHmLFGs/6wGvGWLmoWVdguhVU6UEXPsVil1DIroGz4Y7IwHMGqftkzCKmVezGSVReQ/S4DQKP8i6URtqz8hXBlFlll+7kzfHwIi+/dnYpfRZeeDo6nTpa9AGi43zqElLi2X+XxNzl8pui+kkS/2eABu9/HIgaOr5vbE6XHL6RtKsVDIJNAePzWv+pcIrR/wZq+6K1XZo6vmv/r3yTEve2CzgN6Jeq1oMoGKimwuwpR6xKmRS2+1Z+cBUNSiw+4zEplb4UNtLqVThz2vPWdXZh334ICMgbnSb/FNnO6CcKRteFGniBMI31+POsyXGnbeiSKAj+O3U9H3kUPVyW0me/Akhca7rbb0KG019KPsqBVD9C4dJ625fc2Y/Jp2PAbcRPD/cnh8PUnlKlu9uNSugdQsAEcfa76Cj8oz0578ZNCwZOqOIK6JSnbcj9LWuqOZ8q6uhGsb+JgFGmOXY76DEnO8Qiw79p2cLT78ytMX4WY6AIwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_3_4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362790>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABsElEQVR4nO1Y23bEIAiEnPz/L08f0GyygiJi2z0tD3tJZOQygkr0L39TOBUN2YB75cgEw0e5vkHw0wZMSGrm6bN8z+apQvyVtQDaUERAFTU788Z8iDACu2oIs0TgDOjCNEm3NrYUSufYWUIjzusiLmqBidhfXNfi1lsLdl40ewLO2xOwYm2Uuvz4uuMREwwbPByTJR+mvS5iDjdmrfjeOtOPJXtXmIybd37ErOd7rFXsd0UXrd2Yr2q/pUODiGttDWkbz1disNDqBrHH+z+p2EHvm8SXT7PeOXHLuEJ7N51s+PrmjrRG0nYuBmWcICrC+XjmgO2VekJb7+6TzUqrxet7Pn5tuIT2qD11xJvBe87ck5hzdYzwtXkuw67Me0M6F/oS1aGCSjpFC8RkdnlyLt/nJge3Cti30dp19TR8vvvQpH5mNaajQHIqYy9h1+kEpLRDxcMNBx3ImcsRTsjwOXS3FWNNWEODchLZR4gMceeqGWhrZuX/oFL7PBsRxrYgTcDmWXDr8/m1PlsY5Kqfbrz6w4e56W7FfeWdG/zfcNd88fi7jck7zwdFPNeuQfbLF/NwhTZQiDtYAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_3_3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362790>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABq0lEQVR4nO1YS7LDMAhDb3r/K/MWcWYSR7JxoM2i1aKd2hQjfiYx++GHrwOeNiAFzxH4KzPkAbjB/GkjnoQn2L+YPrPqenCh0fPnJBTwtEdtOnkBR6U682cW+WK0riToO5JdKwFK/mrL/dA1ajJCSMWus0tVlwAh73mbjsDpqz8K96O+Weg4LsDc4wpV2vfc4xq7w0HVUdF1wA5k17OTkU+ZJDKG6PTlNGUqsbOfeZLss25/vepWaoDfaHwN5Z1uKfxiwrtd8cL/ZBUwmKGqubQOILjzQzj54nt5XAo59rupOP5YM+Aiel4PdyYuSFd9t3fsaL3fGOH4W3Hfh7bzPm14vbHh2IimzoWHsQocDbu6VbqZ6gkOOVGEK942Q2du9cnNjbMolfU2tMS6/W0sVe829036ffw6cDVDezuGbIVm+4UJh0grl4SH+ojQqHzkTuWDzZZ417P1XB/TGoKcJAcjZmnaCzKK4zue5ZZ0FkbeWxXXabTVt3STu6HHB57nE/D9Y+oAbPeZkuNeKYyTI/s2tdNnZtbaSEDrjYekSvLF+mpd+W5kXqQ+gn9geXxK28RDjQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_3_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362D90>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABoElEQVR4nO1YSbbDIAyz/+v9r6wuIG2a2EgtBBb52jJYnmQSs3/cE76awFWA4NvfDCILAHPDahIrgTt7T31/iPcI2gCbLSGwlkmed8l5CPoBMx9aZlAi6QYlLwkU5wuNppUam9GJVyQ7P0uPCs7z0FaOo/WF35cxKycpce58vaIZSG9z+RHsutLySYic1KrZYc5HswHbCvW9L/HH01LLZ1bdSxOivZE+crwelNTnZwRJutagmR3LPrrN2wPlhZ7En12HMjkhi2zcAOLzVrEwsuNRSpcHtLXj3TnJrn3m4y0wFxWfrefPkePKNjmpZCXKUMn4blfEj6p9vZ57T99AX6xpReTp491tz7j6fu4j4jzUKUYSD/N0YuRxZYrvrZT4i1jaPh/OB1fJU4zQtHQi9wilOg09jvBjv+dqJFwDOUB5MQ7Q0FZ1ELUXXnd1B0eqp5GsY5Dv74dKADbqoLEY/fmRK8RISCNsBItk1NX6Pq91fKlmZk6Y9fdhq7uDvXG9TayvdL7k9pxhmPd8s3diht1W58z/9zUdjf+od/7DuhRPkS2JM1nHyeUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_3_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362940>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABoElEQVR4nO1Y2XLEIAyTOv3/X3YfOJak64MYJpl2/UoMkg9hAnzsY//OeDcAAJCbcHzdcejJBITccfAjMo8SAGUB21A+IfMALH6crAsJf/09epkYttrqqo+pyIu8AITIFvaZsF7wi4ayk1ebLrDqY6GNR9++tPxkYUSxNvJ7Mg70ClT3F//8uZYPcRfi2POW49XYVOo2fELvt/mDQ9wBdPI1/Bv0jh6iskKNvZhl8+b7mMAQ6Fcdi5/ZeZeMSf9ZbwHo34010O2ep8iOvDfL7PwLl8GsC0woYIchR/fIhSWARIv85IBDhtUOg9qbqpO1gJSrSnvCFILo3dvVuuAR+n0aDb4yV7lSbzI6cQ9CcY8EGvkl7Z5omvDp5QFo6LkQ4cS3zK8QZa0/F87tgcev0E9lC95xyEkNGupXy4REamNaTSLem0ZeQ9eo9gtStPVRKICAtA8hQoIPoGWepZ6y0HdXfQigV/KDKPQJb9uMs25X1jl0mbWeT0PUm/Epf8q6dVVYg2zMxm6uyUFsTNKaf3hlno7NlknLVj0xoYh/2X4Ae9x1WIelwJ4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_3_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362BB0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABpElEQVR4nO1Y267DIAyzq/7/L/s8QFsqoE1C2dSj+WXaRO4mCQN++OF90Jg4n/HiOxBeHsAQBA0W/90IRL+LrA+5MId+Fl5HDCuJrcX3oKZpEMCbukaSLjBHuxS/kAPtU9Cz908COaUcu8pUeSUzI+S9q5ETmZgXSqNULVQ+c+cFdtwI55Onj84ZQTH1RakyX8O0vaqPWWfr4L2032cdYguwpTdaJAnq33erzrb8rfS5TZkycRxKtE8sCMZeuRBDw/rEBYbA0e3b1k1qCAJsNzw76ZvWXS7ZU7XRdMly9jFXE5xe40ZcK0xX7birVvPcJkmmvUCAMnXOykY2PxZ6oPB5Eh6xE7KthGJR+ey+iWOq73eOnQPEDV8ZnmO3YR/Lay/rbbQmgth11EyHYOL2Ewr17GPJMU26BkUoo2wfw90iu+DdeIqHjVGy7ncKT4qTUtY/2RF2QILnVVKdHC2c1NLqV+ve9lYAlKd2NUWGH15tBfOf124LCspdaExDa1yj+5HjfNU9tcvOgN8rT7Im/dmjYuf6LLzb8wQfBx5V/wBf+/v5D4x7nw/SjLU8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_2_4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F66783622E0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABmklEQVR4nO1YwbKDMAhcnPz/L28PRlsrJJCgvpm+vXQaCS6BDbTAP34TUj8JCMD9+0+gBrtGfU3stJ3yg8IDWCqJHAakuhqyvhFl/UiIPR7JVnWPpX4Bdt5T+V8vjQEHD6a/ZDm6PX0JBbMk0JjCaLlFC0azX4Atawn1p8Yhbc/JJWPcoupqaT8+O2lwzVGvt/0lHNoePCEOFV11O7EGs81aXSqEqZjKUY5rmmk5vtxF0zSNrgPgketmOZzWUHbK+12+fQIwrTO3TrLPI/JAXU1rdSOSMOrN0QAa79J2G+bB4GVA9PYWPcapWUtWIX170D2WrsUXKCa5LDF4/Bx+kJ2e0HeA0SGn07SNPREQZE9DBNmykiNNyyyseTPxmV2Qzun1ZFMrXil8zd97ySk1syna+0eag4eN5ldr8qDok1M084TkdboGRm5WwJSYqJUZ1Dwh4XvtwqkwAuW2imZ+HYe0+INTRwe3/MPxkXmv5G/BaNnrWJ3Nal44MZFGkJ955TSHyv565BbYbSlLQfr/urrDv3gc/t/Xk3gBOi96O3BnAOAAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_2_3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362EB0>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABo0lEQVR4nO1YSXLEIAyUUv7/lzsHm2UMQs1ik1TSh5kqQPuGEfnH34TuVqATEFERbNAbr0ssNED6ncdXn+w1QoexKuKX944lzGaARu3hvrPA9iyAfZFfD0DsNL4vI/xN+OD09clgd+RV5N1qyv02E/lVfccO5MM9PUW+qC8XeoWsScjkaCPrP8gVjdM9uHhG44dY6hpdusDJa4UycpiueT+ylyz7mMmitgxRIkc5DwXjuQ7aX4OUFnW2NdLWXCypraNhfTbyvtNcZTuaTcdsUBF4nGO3H2usRMJ4M8HeVo5BLxK7w9OgSpVW/LijfYfL+OptB7xqhViKKqT9UODB5KyKCCwvZX6xOJXLlK5Qv4+G1GIYloeIOR9PDtZVScb1CLvhJfojnhzB2YAa2iDeBd7+ADcDn9k6c8NLYlp7EBk3vcKaDBRz7DJe8dDzyK6XIoi6ky6OOlV/ZnWu7wRECb9nX3XqmGG65ye+A9rXocyM6ccMP7lWg272JKez3EfMeP8dlZ90rmrZ3X6kdne8IVOg1AqXHJogx4bx/QhWfz38CnwDhkp+MjxY05kAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_2_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362D30>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABm0lEQVR4nO1Y27KDIAxMOv7/L+95sFKUJCxyqTOn+9IOhmRzBRX54Yd/ByVkIKIioGRXAffI4OQxoWP3+lm+36SD/efYuo0184gQ+VWhIikCwjjPuoO6yBrUiGgSeJGqqJQqHalvoinzJGK32QEFQlcfkwzjnA9hlaJZTHtX9owOeKpLs69s0YRGDx1p0yZAT4W5vfPRnjIfMiNpR2IqgmvtX06ebL3Hfb7/qgPvIDM8G36kqFB7fCqbkf/Z0n/XOwyoQ7U4OVpH2HMAOZVbfeBdLgZ1WceuFvG1A957T1JfTRZWZKK1o4hiFApBiticCARyLaayLNW1bMWeSSgTv78yXJfNBrlhrkG2ZpFiFB8Y3klnrNdPRXasxaCm/QBA9Ezp7aB5n1FdUIpylP0QU5ESiF4KWmH3fHo6iUmOz7SPRl5/cLQwEXblzW8VjXiXvQJW841Dm+4hI6iOI/M6d+IruCMsyXc9bsPut5/6qUVhWOs1RyogX2lXfqMYcL0l9x+XHG3YMxUTb/YFssw/4yPcygSk14DFdh+BPx9fhCP1lC7MAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_2_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABp0lEQVR4nO1YXQ/CIAy8Gv7/X64PGwxdv4BissR7MDrotaUH1AF//PHHU8AJHK9GxgyAMzh/g4RIS6Oi9jmPVftPskSunhYtyFKfrHpKl8weDfLxcWRbK2/mHqwBjS3h0oLPGtNhfKCg+6UwhmqQr9E9qgcAOjMq9jQgeSN/MR+xaGO7PNdqvsxZGIxAmylpx9ETgUGbNn7FUXniQDguVHtlwFnUwapXJ75ZK2fpn6UEofgTeExNeZW4mVLI7MP2kj2DpGBG5KDnQnSTMFHtrEyMtV2RPXrdXVeTo5ltPHQBsBruQCWH0DGWztOiI92cjCGw2EXwSaesjELoF547Y/KuuqSV51sDdEpNVxyAUdmFcq9TmCL3fLjJNrb8fefSWdtJ0ctqcQMl8aviisEcOJU0825wTkKaldg4RANtcCtPUenbuQfDWTEjdnfRF/wOL+O839+sAQCRcKNa6JI3rJbvAbGFmOczTqERP17lc+qVcZP2dEkrGZF97K+NFdEPX45NdqRijtZ1FEcOS8zVnBt5zR70ShOYD/dZWcoYyz2y55+DwVc/bz3UiB/hhWqdAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/data_2_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAABnElEQVR4nO1Y2XLDMAjc7fT/f5k+WGlcgUBgqXEn5SETW+ZYLaAD+Jf3FG61LgAB2exlnchKW/L8vaN8qDfjUCUJ4/aMa/AjEYHLojE+g/2VafE5/SWBIFQxH33+X1oS88wDcLkkwd0NdLEkwbtElYAHSsphlCqZvjSf9mnh0evdbwR+XaSxe0aUmxz4oH+LHr1c04JsSjWXTyWOIllX86Z5AX2dEBfJk+Fw9RxOtqWpmXesG8xGkfgaO3p9IsZM2oeh0ni8ho+9egzNTg7z7Tx4gdM6gBpMPlSHoISnwdgFIVbC2Q568E7NfOtns38o0tw5mJjeMxKAdGAHkzvNPM2/OcXKJ6ycEAg5MyQDwhT4C6ymVdsaNL2ExFnf8rNLfIrdfNdtcvbs0gX8QWIwVWyVZLZepboM/CA7p8jyrZ46/kGhWyXOkPKU3OT8unTLJbny5NSBv92liw6I1SC1Wpf29Xndc5Y9VrpFtjc2vFmPV9SPllUzaeTLdvChZKGUk1472n3zsmw3eFgDiiGba8SfunYqXwiHx8s3lC+01nw5bN3BGAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_3_4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAB6ElEQVR4nMVYW5IDIQiErdz/yr0fmYmvbgXHVPhIpeQhLQg4ZkcJOGvvOb0SsjAzp+ts9VsEE24Uds1NuAYzp1jg7O9XqCTIZKPIgbNMgxnPwbKWy9B0PgMIKdUyPEUlPvNjlwyWTm7//CzkKif/Jqb6JYWt4mT8dXdtU1FQvohRgNyKdn4GC8Akq7II8/WMR1BYkc74DaKXAGSc/Pqll/pct2EAA6k4soxVGvjy2jCeu7zq6SpNi8y0BKuN37jaNrRyZxIoMAPhwBa9TKO3aZ9zg0LEsvBT6riKb5VZbojszWUlgCJB+Xw6CKVbN5cE8dZiok1QtaVxnkHcq1hkdjpJSwyg2Hs7WXhYo57vbFvpJCKYM7ygWIZekklqNEaAMN2I9oJIbblizDYNRr12k/ZB8M03LwPzKm6qlYwgbCVoim5NiaPtmVdu4TrT21o61mjIO7hV+WR52q2EGEq3ryBeM+MtQwAqGGsn5QH0CB+9i32h7AaU1sQmGWXggVd0toyElX8imRC6Ah0f1X7xOUkcy3xWbrkSIK8Lpwi+O2cuGujAIwBxv9R6ww+o03aoL3SdVi8Snw9uGouMG1j1OkvxLlETsKwwdKfBDll/9G7Jn/tb7cQhZ6roJm3CO0TBYfvZw/OH+Owf6DWkMCD5WFEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_3_3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAB3ElEQVR4nN1YS5YDIQiEebn/lWsWHbttQQrFN4thlUQo/oJR+TOC6KqArIpY+qkCEAJ2jq5zERWXB2CyD+UihDzrKKnexwYZYkJlnvZ0OSQy2MKVj9rbkvHDl1R1kqCef+ZGKNrr+xA2gYgud0+WFNhFVl7gedpKXZNtwj5I1KOxalJQ7fRdonDbt+LfnfsJSNiEBbW37Of1o4qIqZq4QHn5BhyQ8e7pqFC/8kSuc/ALx4rbABEXVQBRXPg3L249ofBuEh85B95kkMTxBpvzOfrA507IElv1nNpbdAwaDaJyJhXoYBEvlEQIEmQc3BsJeonOZY0/YC2GMAS5K1TsoK+MvHhwGxOIokOj12wyJdwF4URhF1Q9p2eX7dLEtJS5tRgZB2s2BnF9r9oaM1NL6HBpG8vooG2jtcb6G+I3MBqX04MFD88uXtlycBnaW8X2oOthyrq4pnqb0MbKHhq4OpFvFJznkh1Q17bF8E4/quYbLK2pboR670FnwibKdOMvl72KxtIQpQ9eqm+HMgv9zIXFDS7n4Jm1sCNlkPMI5A2BiO+gAc/4t1qhMXexYNrLT1IZPJ6+jMraxgjcz1T3uaTzrwFqxaTDpJiavfCX6iBYsMcacQ7LG/T/in4BRBKyHQlzw/YAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_3_2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAB30lEQVR4nN1Y27LDIAiETP//l/c8pGo0CyIm05mzT63cFvAakX8O7f/iPlQlfDwPkPgZN76LXgoRpZmAKG8BBoOotZKfFJ/+r4ooWE1URKhAvLbbBI1CRhEwZWSBEp4wanLmzZTYBJYtaDjLTVE5roNqqutUvsp3J7+Qm28DDzY4M4pLcIIR21nQ83pW+WcUsLjn4MQnX6A6N8xAq0+rTmV83GSMjQS+NwsY2BACWcCtXRsfO8iNkhPKPqLcpkZ2ZYV/AFbZPUFiR1sQwNfTqrVetkkzCW06bqZDgmAuYc7cgdZzqNOPEio6EKN6l8E+QVi9yvbwjJbLvfTfrq3O7mkSOib85VyVbOz11rM2ozajw1IJhngfm4fMLUEjm50lSCiu3HzW6wsRKdeL4y4atSMB/BlK7jLhDHMNRN1/IlM0AvdMUpKORi/obn3t/acEHRO0LHwyU6osw1CKOytQRcYEzYdSyNeqgj7wnJ9Guz94R11g+jgtz8jcVdVHcobWX12CNKBiTl0Tr3rvkuIzWkLfQePFM9lIEeN6/7718gELkT7BwL3A8JM6qkJGuRqgfIHoHTz/ZfDieogUC5VlBNFiq/3oWwjdFohZllLbEsiD93nkS7dv187BNxv4Q/wB0j2hOB77m8MAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_3_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAB5klEQVR4nLVYURbDIAgje7v/ldmHa2sVNLGWr61FCKAQayaIu7uiPzP3gmYnEHTdDC6tGBsbA6g88U69s/hRQAGGIJsLZfUTc754JZNAC1Cw8sfkaB8vomkNxe4IzXyhSRWMimdmhj5tHI79mmZmBtQLlC06yCMVYa3ijklZVpIWeJLOYOgSLBwVL4JfumhNZgCSAIH0TyKlAQU+nR9YX06tsk0/HOlQ6OBxeyldxLnWowbY99DjSE/d6RsN1xCp/P5/YpCkytURYD8hA/FeB05OYb2AZsehWJ5sdgWIauRmFjxK2iiRA1w0SmRTMPd7e1NtURzvgkLloBzkYViVJBCWvjVn8ORPAvmjariTpBd7w6l8STwm0sX9i7PuijwZ4imSQ+6m4wDTbUEqTgFtiJB0lQx6oQesEg36DiL2mOZFGODWG8xp8UY+Zkx0JoMtwNwH2aQJ/dPbgQZ2wCR3mOS5X97MLGYyagE5oB29IuPLcpiNJ9xJi0DVNrSFqmjPrYURejvFwy2aJC14XPadepMwkhqKNotZ3I93UEF6RhQmSgKtyHICbof0ZuXrUmMwo3USiDclCjDmnAI/TWXvdKes9WfwHYrBXhq3C/vJ4uEHX5grFJ4R8iIabNFXsgxfOK0Doa39ALhGoziq88E/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_3_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAAB20lEQVR4nL1YSZLDMAikU/n/l5mDXB4jdqwZLklZ0KKRzGLQYWGcAiKiA1ifJyQzz3z5NZsBWJhE6KNpAluMeBS0x6nNADzMHtpFTpp8pM4gaA9oDU9WUCNz+ahBb90+AJvNRvBt/JWrzDlFa7kfaRDt5Ig0wdFbFHkDIHXWimoz0gzHQhOcCIx/Yjli6K21Io2y/iyRXvnXNQ5RI6O6N84W3zLA2su5OeC4ACJwtMm9WR910nOMV8YO8vad95ROFJlgx1UK/a02UAemeoKXeXAS60WT8eXbYJCdXX5XqKVK9S5PUnqwWuiNPA0upYNbx9upmUWb/N6U1Zop1J9NFMEQt92IcaFgv+otUvSNYHZCXX5F953rVbHNdHqtWjvYdzpw5cpMbjsaS64jCb4ddqz6kAoz5d1cvqMDoaaJ2JfB9vmpA9N2VPgD8yYIgmvVz85pnI+NuyMsgJPawulU3+pUWfy4SmxrTV/B7dlXLKVZD9z+5jIsE4f4Pa8oE6l52PDm5DWkR/O34Q6r44FPJs0BJr3UzkUu9Wn2lkIa41JbwKXRhq0JpCIGP610ZqJ3pFQlYE54U8bKqn2C3Q8JBSWevjjSys6Qf3lFq2K4NaH8buC9Nz71Yfe/5AdrjMHxWr6QAAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_0_4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362940>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAB8UlEQVR4nOVY0XLEIAiEm/v/X94+xKQmAi7otdPpvtwlArKKQBT5x9DuP25PfxGQFIVvWTyefwKIpgwHfZMJjY68ysc2H2LQgOFEP1rzp8bg8AWYiFUAYDBsvRu86VfoUBolxsmmRn2B3j5w+60CjlOEVXhPrksB9+fQ6ynRB42qAAdzmr8h5mWTNHdKhZI58I71unMHKpVYM6utuphfNiSnkzxE4RjV84dib8lo9dS467MnMZ/kFVN7KyFnrhvh/0OkvIr2hC9vgNDlZdRYlRqPUyvwxQuWcQMu8rActKatypTIPpWak4GtTJNzkicaw/rGi4hAC6d03JAdW3ThFvbbN65TriUoHYqzdt3HiksiF/k9fV0q3XHQwaq2wmsm6FwVuLK9zHLpQm1ZKUtGnJNF9w5rWYYOz9VlkPueLIdb0NanVuUgvxCXJIwJFti7s+R49O3tatRDvNRmWyYaq5lXtKS5vWTYs1814GWlfTjR0oQ9gVMEnNVvYzrJlOQeORcQwbGanrhRwFGJmj/b/SPsFeZdSw/+NI1FI2rIZtbodIR8GWhnXsttSA+3VgbXdPGstkH/M8mzZr9/h6NZxPFoDUznNcvEJrznIusTumtSob4RLPkEuKunLedsEVvJt7NIkfp15rsBq8x+5DJ8D74A5h6/B86Bn/cAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/train/bundle_0_3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=252x28 at 0x7F6678362B50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAAcCAAAAABghI05AAAB10lEQVR4nOVZyXLFMAiDTv//l+kh68QSRiTpm2k52hY7GCdm/5j8g7LDoyM/zB7SW2OSyY0etxZGx0FSWCxxItEKs2sgZ+6IhB3TYBDyAkWyhvbW1bjuDQsTURFTxJxjGfhdF5A6fE3hK9AjpDj5yV8MqHE8YOPSF1VCYGJmTtdndHWYuy8gnASVrK8mB4x8BmbCh6DvAHx+ayCY2XpGCPJJr3Jh4MhzmYnjtWL0Qn1DUUx+oxhQ5FOVqAy5vOcJDBThup2kY6eNUBj59l0iBL90Y7UUqStBGl6PdTjQlpX8PVFAzOR4rdtPsp42Ni1QlbPqLanC5Mgz62lTT5bzWMnTzNI/BRgyPvccsV4szxdGVJf9JUe+UF2X050tup8Jd98HI3SJjuzGqy5sVr9sngEQ9g4oBJ4JyW5U37SvZRa95+UJWhlvfQG0ct8jA7rSfOB466aNlpTaL7BNC7yema+IpDUvP21IiVIO+rV8cG3EBUGA8Y+9GI01n7Ux9VPrVkYdhNI+V4ppzXvzuOMF07PHVcNv5ZrPebCvWGCNqnmnn0xsF1hT42lmEebj8q3EpvQO1517ZfQkoPdp+g3gpiYROotfM/5RQinU+QL/yZ8fbdK7/R+iHz1KqRyM/NE/AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/test/bundle_0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362400>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAABZElEQVR4nN1Yyw7DMAiDaf//y96hr6xxKsPoQ/Nl0koCxkDSmv05/GwHuMDHEU52jku8HKHYNdiW4F6obTleyXWgf3IqnB7MnW9TinfdVnO39XQYi4Gq9cgSJHVobgNleyBHL5EWRjDn3b9+2u2GUaVkDI5l2oOZzvDxylHRZvhBjW2xK+xBM6NkCAuHJfVTl6x5qCVI0ssz7pEzYk1RJiXFCu4DgG0U+7mkhdukKMBvMS0l2KnVDIRvNjA3g8hwE1DWfWuBWgX3zn3waPLt0sBoCjSSlQXZmwwNRTfMHw/i7Wd1UKqgHPbBmbLHKlgkJ83OVMGrLv+CH9LWt5Vo9Hqg2eeSPa/it//0PVhvf5hrblojuInBtQdLJcEA1Hk/hbq0rJiV8ck7Pz7/JU0FzJp4gFBoky3rwVu/oRzAacHF8VQBo4vHCv4Vql+XqvHzV8ee4HMq9KoPbzfil4H+oMPgVHwAW0VsK2LcHeYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m/content/drive/MyDrive/Project/NeuralNetwork/data/test/bundle_1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x28 at 0x7F6678362400>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOAAAAAcCAAAAABdFuxfAAABUklEQVR4nO1Yyw7DIAxLpv3/L2cHuqmQJxZslVafphIHG2jISnTjxo1ZCEwUISKB+V9CJtAdbsSe/lihqJ9gN3x/xPrhc/esCAydME/tIK6UcWVKQXAWzH168/S43kGBVGLWXLHrUDyiAlqAeAljLmHJYCtOeeYxoMATxURLKLFY4yWDXJjYCsh40PseL7NKWa+iDJafkGepPZ5B76cQDzWkbjD3ZwsKedqFHASHlmTTGlbdgxC42TEXJtg+r86bb0TZYHpi3CWPeExE0oW0n/5dxTJ3enWr5nFXthd9AE9VG+YpJdVetHD9mxERTz7NsXm/RDMFAUOu+kUPIeTxUVC2djOjQVORnAY8NRYx4yHO2pGoMys7eCp0U40qyqskLg8pg4YSVeOKQHlhTpG5dD+9B10EBniyw1lmcPv/HnCipZ8sroDR/2Dw6t+jbvzfDr0A7atkOJFEbNMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  array([1, 8, 2, 3, 5, 7, 6, 9, 4, 1, 4, 7, 3, 5, 2, 8, 9, 6, 0, 1, 4, 2,\n",
              "         3, 6, 8, 7, 5, 2, 8, 4, 9, 3, 6, 7, 5, 9, 5, 7, 8, 6, 3, 4, 2, 1,\n",
              "         6, 8, 7, 5, 9, 4, 1, 3, 2, 8, 7, 5, 6, 9, 4, 3, 2, 1, 4, 6, 3, 5,\n",
              "         2, 7, 8, 1, 0, 0, 1, 6, 7, 5, 2, 3, 8, 4, 1, 8, 7, 2, 6, 5, 0, 3,\n",
              "         4, 8, 1, 2, 7, 3, 0, 4, 5, 6, 8, 2, 5, 1, 6, 7, 3, 4, 0, 9, 8, 7,\n",
              "         1, 2, 3, 4, 5, 6, 6, 1, 3, 5, 2, 4, 9, 8, 7, 6, 9, 7, 8, 5, 3, 1,\n",
              "         4, 2, 9, 6, 7, 8, 5, 4, 1, 3, 2, 1, 2, 7, 9, 4, 8, 6, 5, 3, 6, 9,\n",
              "         4, 3, 8, 7, 5, 2, 3, 5, 7, 4, 8, 9, 2, 6, 9, 8, 2, 3, 5, 7, 4, 6,\n",
              "         7, 9, 8, 6, 5, 4, 3, 2, 2, 3, 4, 8, 6, 9, 7, 5, 8, 7, 6, 9, 5, 3,\n",
              "         4, 2, 1, 6, 3, 9, 2, 8, 7, 5, 4, 1])),\n",
              " (array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
              "  array([1, 3, 7, 2, 8, 6, 5, 4, 1, 2, 7, 3, 5, 4, 6, 9])))"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "train_data_path = '/content/drive/MyDrive/Project/NeuralNetwork/data/train'\n",
        "test_data_path = '/content/drive/MyDrive/Project/NeuralNetwork/data/test'\n",
        "\n",
        "def read_file(data_path, one_hot_label, flatten=False):\n",
        "    img_size = 784\n",
        "\n",
        "    x_train = []\n",
        "    t_train = []\n",
        "\n",
        "    for foldername in os.listdir(data_path):\n",
        "        bundle_path = os.path.join(data_path, foldername)\n",
        "        if os.path.isdir(bundle_path):\n",
        "            images = []  # list to store all images in the bundle\n",
        "            for file_name in os.listdir(bundle_path):\n",
        "\n",
        "                file_type = str(file_name.split('.')[1])\n",
        "                if file_type != \"png\" and file_type != \"jpg\":\n",
        "                    continue\n",
        "\n",
        "                img = cv2.imread(os.path.join(bundle_path, file_name))\n",
        "                label = int(file_name.split('.')[0])\n",
        "\n",
        "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                \n",
        "                retval, dst = cv2.threshold(gray, min_therehold, max_therehold, cv2.THRESH_OTSU)\n",
        "\n",
        "                dst = dst.astype(np.float32)\n",
        "\n",
        "                flattened_img = dst.flatten()\n",
        "                flattened_img = 255 - flattened_img\n",
        "\n",
        "                img_processed = flattened_img.reshape(dst.shape)\n",
        "                \n",
        "                images.append(cv2.resize(img_processed, (28, 28)))  # add resized image to bundle\n",
        "\n",
        "                flattened_img /= 255.0\n",
        "\n",
        "                x_train.append(flattened_img)\n",
        "\n",
        "                if one_hot_label:\n",
        "                    one_hot = [0] * 10\n",
        "                    one_hot[label] = 1\n",
        "                    t_train.append(one_hot)\n",
        "\n",
        "                else:\n",
        "                    t_train.append(label)\n",
        "                    \n",
        "            # concatenate images horizontally and display the result\n",
        "            if len(images) > 0:\n",
        "                print(Fore.BLUE + bundle_path)\n",
        "                bundle_img = cv2.hconcat(images)\n",
        "                cv2_imshow(bundle_img)\n",
        "\n",
        "    x = np.array(x_train)\n",
        "    t = np.array(t_train)\n",
        "\n",
        "    return (x, t)\n",
        "\n",
        "def load_custom_data(one_hot_label=False):\n",
        "    return read_file(train_data_path, one_hot_label), read_file(test_data_path, one_hot_label)\n",
        "\n",
        "load_custom_data()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx0UVnxyo3tX"
      },
      "source": [
        "### Use MINIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na81Nc7bvCN4",
        "outputId": "66c368bb-cd06-4865-a528-66a3baae8670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting train-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting train-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-images-idx3-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Converting t10k-labels-idx1-ubyte.gz to NumPy Array ...\n",
            "Done\n",
            "Creating pickle file ...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "# coding: utf-8\n",
        "try:\n",
        "    import urllib.request\n",
        "except ImportError:\n",
        "    raise ImportError('You should use Python 3.x')\n",
        "import os.path\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import sys, os\n",
        "sys.path.append('/content/')\n",
        "\n",
        "url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
        "key_file = {\n",
        "    'train_img':'train-images-idx3-ubyte.gz',\n",
        "    'train_label':'train-labels-idx1-ubyte.gz',\n",
        "    'test_img':'t10k-images-idx3-ubyte.gz',\n",
        "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
        "}\n",
        "\n",
        "# dataset_dir = os.path.dirname(os.path.abspath(\"/content\"))\n",
        "dataset_dir = \"/content\"\n",
        "dataset_file = dataset_dir + \"/mnist.pkl\"\n",
        "\n",
        "train_num = 60000\n",
        "test_num = 10000\n",
        "img_dim = (1, 28, 28)\n",
        "img_size = 784\n",
        "\n",
        "\n",
        "def _download(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    if os.path.exists(file_path):\n",
        "        return\n",
        "\n",
        "    print(\"Downloading \" + file_name + \" ... \")\n",
        "    urllib.request.urlretrieve(url_base + file_name, file_path)\n",
        "    print(\"Done\")\n",
        "    \n",
        "def download_mnist():\n",
        "    for v in key_file.values():\n",
        "       _download(v)\n",
        "        \n",
        "def _load_label(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")\n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            labels = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return labels\n",
        "\n",
        "def _load_img(file_name):\n",
        "    file_path = dataset_dir + \"/\" + file_name\n",
        "    \n",
        "    print(\"Converting \" + file_name + \" to NumPy Array ...\")    \n",
        "    with gzip.open(file_path, 'rb') as f:\n",
        "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(-1, img_size)\n",
        "    print(\"Done\")\n",
        "    \n",
        "    return data\n",
        "    \n",
        "def _convert_numpy():\n",
        "    dataset = {}\n",
        "    dataset['train_img'] =  _load_img(key_file['train_img'])\n",
        "    dataset['train_label'] = _load_label(key_file['train_label'])    \n",
        "    dataset['test_img'] = _load_img(key_file['test_img'])\n",
        "    dataset['test_label'] = _load_label(key_file['test_label'])\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def init_mnist():\n",
        "    download_mnist()\n",
        "    dataset = _convert_numpy()\n",
        "    print(\"Creating pickle file ...\")\n",
        "    with open(dataset_file, 'wb') as f:\n",
        "        pickle.dump(dataset, f, -1)\n",
        "    print(\"Done!\")\n",
        "\n",
        "def _change_one_hot_label(X):\n",
        "    T = np.zeros((X.size, 10))\n",
        "    for idx, row in enumerate(T):\n",
        "        row[X[idx]] = 1\n",
        "        \n",
        "    return T\n",
        "    \n",
        "\n",
        "def load_mnist(normalize=True, flatten=True, one_hot_label=False):\n",
        "    \"\"\"读入MNIST数据集\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    normalize : 将图像的像素值正规化为0.0~1.0\n",
        "    one_hot_label : \n",
        "        one_hot_label为True的情况下，标签作为one-hot数组返回\n",
        "        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组\n",
        "    flatten : 是否将图像展开为一维数组\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    (训练图像, 训练标签), (测试图像, 测试标签)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dataset_file):\n",
        "        init_mnist()\n",
        "        \n",
        "    with open(dataset_file, 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    \n",
        "    if normalize:\n",
        "        for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].astype(np.float32)\n",
        "            dataset[key] /= 255.0\n",
        "            \n",
        "    if one_hot_label:\n",
        "        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])\n",
        "        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])\n",
        "    \n",
        "    if not flatten:\n",
        "         for key in ('train_img', 'test_img'):\n",
        "            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)\n",
        "\n",
        "    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) \n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init_mnist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjRQLf1HjZZY"
      },
      "source": [
        "# Functions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4IRMbnVNRwY"
      },
      "source": [
        "## Basic Funtions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnVM4bfSjk0t",
        "outputId": "afe6f445-e4dd-49af-d2f6-0986e4081d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 0]\n",
            "[11  9]\n",
            "[13  8]\n"
          ]
        }
      ],
      "source": [
        "# Activation Function\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def step(x):\n",
        "    y = x > 0\n",
        "    return y.astype(int)\n",
        "\n",
        "print(step(np.array([1, 3, 0])))\n",
        "\n",
        "# Old and widely-used activation function.\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# There are three common places of these three activation function:\n",
        "#\n",
        "#  1. The output is between 0 to 1\n",
        "#  2. Both is liner function\n",
        "#  3. The more important the input is, the bigger the output is.\n",
        "\n",
        "x = np.array([1, 2])\n",
        "w = np.array([[3, 4], [5, 2]]) # The row number should equal to x's length.\n",
        "\n",
        "# Diffrent operation order will output diffrenet result\n",
        "print(np.dot(w, x)) # [11, 9]\n",
        "print(np.dot(x, w)) # [13, 8] [1 x 3 + 2 x 5, 1 x 4 + 2 x 4]\n",
        "\n",
        "# Central Difference Derivation\n",
        "# We use 2 h to reduce the deviation.\n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4\n",
        "    return (f(x + h) - f(x - h)) / (2 * h)\n",
        "\n",
        "def func_1(x):\n",
        "    return 0.01 * x ** 2 + 0.1 * x\n",
        "\n",
        "x = np.arange(0.0, 20.0, 0.1)\n",
        "y = numerical_diff(func_1, x) # This is a valid operation (boardcast)\n",
        "\n",
        "try:\n",
        "    is_training\n",
        "except:\n",
        "    plt.xlabel(\"x\")\n",
        "    plt.ylabel(\"y\")\n",
        "    plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "def softmax(a):\n",
        "    c = np.max(a)\n",
        "    exp_a = np.exp(a - c) # e ^ (a - c)\n",
        "    sum_exp_a = np.sum(exp_a)\n",
        "    y = exp_a / sum_exp_a\n",
        "\n",
        "    return y\n",
        "\n",
        "def softmax_batch(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T \n",
        "\n",
        "    x = x - np.max(x) # 溢出对策\n",
        "    return np.exp(x) / np.sum(np.exp(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "428IuPKjnPPa"
      },
      "source": [
        "## Cross Entropy Error\n",
        "\n",
        "We want the loss function result as small as possible.\n",
        "\n",
        "We introduce loss function to find a params that generate small loss function result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "id": "wEBMqCA-nRWg"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    delta = 1e-7\n",
        "    return -np.sum(t * np.log(y + delta))\n",
        "    \n",
        "def cross_entropy_error_batch(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "    \n",
        "    # Only output the index of the right anwser.\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1) # 1 is the max\n",
        "    \n",
        "    batch_size = y.shape[0]\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lnw14Dwl-hc"
      },
      "source": [
        "# Graident\n",
        "\n",
        "In vector calculus, the gradient of a scalar-valued differentiable function \n",
        "$ f $ of several variables is the vector field (or vector-valued function) f whose value at a point is the \"direction and rate of fastest increase\".\n",
        "\n",
        "The most basic way to find the gradient is to use the numerical differentiation method.\n",
        "\n",
        "$$  grad(x, y) = \\frac{f(x + h) - f(x - h)}{2h} $$\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "    \n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "        \n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "        \n",
        "        x[idx] = tmp_val # 还原值\n",
        "        it.iternext()   \n",
        "\n",
        "def test_function(x):\n",
        "    return x[0] ** 2 + x[1] ** 2\n",
        "\n",
        "def gradient_desent(f, init_x, lr=0.01, step_num=100):\n",
        "    \"\"\"\n",
        "    lr is Learning Rate. This should not be too large or too small.\n",
        "    \"\"\"\n",
        "\n",
        "    x = init_x\n",
        "\n",
        "    for i in range(step_num):\n",
        "        grad = numerical_gradient(f, x)\n",
        "        x -= lr * grad\n",
        "\n",
        "    return x\n",
        "```\n",
        "\n",
        "There are four mainstream gradient desend algorithum."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def numerical_gradient(f, x):\n",
        "    h = 1e-4 # 0.0001\n",
        "    grad = np.zeros_like(x)\n",
        "\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        idx = it.multi_index\n",
        "        tmp_val = x[idx]\n",
        "        x[idx] = float(tmp_val) + h\n",
        "        fxh1 = f(x) # f(x+h)\n",
        "\n",
        "        x[idx] = tmp_val - h \n",
        "        fxh2 = f(x) # f(x-h)\n",
        "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
        "\n",
        "        x[idx] = tmp_val # 还原值\n",
        "        it.iternext()   "
      ],
      "metadata": {
        "id": "M27N5dUxQXKn"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6gWqIjrNrdg"
      },
      "source": [
        "## SGD (Stochastic Gradient Descent)\n",
        "\n",
        "We can get new weights by:\n",
        "\n",
        "$$ W \\leftarrow W - \\eta \\frac{\\delta L}{\\delta W} $$\n",
        "\n",
        "$ \\eta $ is the learning rate, and $ \\frac{\\delta L}{\\delta W} $ is the gradinent of $ W $\n",
        "\n",
        "The SGD sucks when the function is not anisotropic.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "fXadNma1P0XQ"
      },
      "outputs": [],
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        for key, val in params.items():\n",
        "            params[key] -= self.lr * grads[key]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmwLtamENzTh"
      },
      "source": [
        "## Momentum\n",
        "\n",
        "This method can make the gradient reach the extreme position faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "cSR-RnRXN2j_"
      },
      "outputs": [],
      "source": [
        "class Momentum:\n",
        "    def __init__(self, lr=0.01, momentum=0.9):\n",
        "        self.lr = lr\n",
        "        self.momentum = momentum\n",
        "        self.v = None\n",
        "    \n",
        "    def update(self, params, grads):\n",
        "        if self.v is None:\n",
        "            self.v = {}\n",
        "            for key, val in params.items():\n",
        "                self.v[key] = np.zeros_like(val)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]\n",
        "            params[key] += self.v[key]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvmXJIvTQFwR"
      },
      "source": [
        "## AdaGrad\n",
        "\n",
        "AdaGrad (Adaptive Gradient) is an algorithm for gradient-based optimization that adapts the learning rate component-wise to the parameters by incorporating knowledge of past observations. It introduces the **learning rate decay** method. Compared with the momentum method, this method will gradually reduce the learning rate.\n",
        "\n",
        "$$\\Delta w_t = - \\frac{\\eta}{\\sqrt{\\sum_{i=1}^{t} g_{i}^2 + \\epsilon}} g_t$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "zL6TPk60QiFL"
      },
      "outputs": [],
      "source": [
        "class AdaGrad:\n",
        "    def __init__(self, learning_rate=0.01, epsilon=1e-8):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epsilon = epsilon\n",
        "        self.cache = {}\n",
        "\n",
        "    def update(self, params, gradients):\n",
        "        if not self.cache:\n",
        "            for key, value in params.items():\n",
        "                self.cache[key] = np.zeros_like(value)\n",
        "\n",
        "        for key in params.keys():\n",
        "            self.cache[key] += gradients[key] * gradients[key]\n",
        "            params[key] -= (self.learning_rate * gradients[key] / (np.sqrt(self.cache[key]) + self.epsilon))\n",
        "\n",
        "        return params\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sOU-gn9YqEA"
      },
      "source": [
        "## Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "81T5whX0YrnH"
      },
      "outputs": [],
      "source": [
        "class Adam:\n",
        "    def __init__():\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZJkBsNk8NQ"
      },
      "source": [
        "# Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O3UbAWBlY5f"
      },
      "source": [
        "## Relu\n",
        "\n",
        "Return x if x is larger than 0, otherwise return 0.\n",
        "\n",
        "$$\n",
        "Relu(x) = \\left\\{\n",
        "    \\begin{array}\\\\\n",
        "        1 & \\mbox{if } \\ x > 0 \\\\\n",
        "        0 & \\mbox{otherwise }\n",
        "    \\end{array}\n",
        "\\right.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "EWaHBc_BlFmK"
      },
      "outputs": [],
      "source": [
        "class Relu:\n",
        "    def __init__(self) -> None:\n",
        "        self.mask = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x should be a numpy array here\n",
        "        \"\"\"\n",
        "        self.mask = (x <= 0) # An array represting wheather each element is larger than 0. [True, False, False]\n",
        "        out = x.copy()\n",
        "        out[self.mask] = 0\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        \"\"\"\n",
        "        Set all the `Ture` in mask to 0\n",
        "        \"\"\"\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sas1Bu3nlPqI"
      },
      "source": [
        "## Affine\n",
        "\n",
        "$$\n",
        "Affine(x) = X • W + b\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "3_yAy2vhlR8T"
      },
      "outputs": [],
      "source": [
        "class Affine:\n",
        "    def __init__(self, W, b) -> None:\n",
        "        self.W = W\n",
        "        self.b = b\n",
        "        self.x = None\n",
        "        self.dW = None\n",
        "        self.db = None\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        dot = np.dot(self.x, self.W)\n",
        "        out = dot + self.b # Boardcasting...\n",
        "\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdcMMpfamwXf"
      },
      "source": [
        "## SoftmaxWithLoss\n",
        "\n",
        "The Softmax Loss is a widely used loss function in the field of deep learning. It is also referred to as the Cross-entropy loss with softmax.\n",
        "\n",
        "Let us consider the training data, denoted as 't', which is assumed to have undergone one-shot training, represented as follows:\n",
        "\n",
        " $$ t = (0, 0, 0, ..., 1, 0) $$\n",
        "\n",
        "Here, $ t_{k} $ corresponds to the correct answer. The predicted result, denoted by $ z $, can be expressed as:\n",
        "\n",
        " $$ z = (z_{1}, z_{2}, ..., z_{C}) $$\n",
        "\n",
        "The corresponding loss function, 'lz', can be formulated as:\n",
        "\n",
        " $$ l_{z} = \\sum_{i=1}^{C} t_{i} log(z) = -log(z_{k})$$\n",
        "\n",
        "In comparison to a linear function, the logarithmic function better represents our desired objective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "3tKcHjDbmyIJ"
      },
      "outputs": [],
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self, print_result=False) -> None:\n",
        "        self.loss = None\n",
        "        self.print_result = print_result\n",
        "        self.y = None\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t \n",
        "        # Teaching Data. Marking the right answer.\n",
        "        # Set right anwser to 1 and wrongs to 0. For exmaple, [0, 0, 0, 1, 0, 0]\n",
        "\n",
        "        self.y = softmax_batch(x)\n",
        "        self.loss = cross_entropy_error_batch(self.y, self.t)\n",
        "\n",
        "        return self.loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        if self.t.size == self.y.size: # 监督数据是one-hot-vector的情况\n",
        "            dx = (self.y - self.t) / batch_size\n",
        "        else:\n",
        "            dx = self.y.copy()\n",
        "            dx[np.arange(batch_size), self.t] -= 1\n",
        "            dx = dx / batch_size\n",
        "        \n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVQCcg1HWvr"
      },
      "source": [
        "## Batch Normalization\n",
        "\n",
        " $$ l_{B} \\leftarrow \\frac{1}{m}\\sum_{i=1}^{m} x_{i} $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "metadata": {
        "id": "X9qF09xwHaU8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout\n",
        "\n",
        "Dropout layer will randomly delete some points. Since the network differs every time, it's similar with intergrate-learning(Use multiple models to learn and get the average)."
      ],
      "metadata": {
        "id": "wl7kCVngnOUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dropout:\n",
        "    def __init__(self, dropout_ratio=0.5):\n",
        "        self.dropout_ratio = dropout_ratio\n",
        "    \n",
        "    def forward(self, x, train_flg=True):\n",
        "        if train_flg:\n",
        "            # Replace the item large than ratio. [True, True, False, ..., True]\n",
        "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
        "            return x * self.mask\n",
        "        else:\n",
        "            return x * (1.0 - self.dropout_ratio)\n",
        "        \n",
        "    def backward(self, dout):\n",
        "        # Same with Relu\n",
        "        return dout * self.mask\n"
      ],
      "metadata": {
        "id": "Chbap8VQnXK-"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F104OfzFpsmz"
      },
      "source": [
        "## Convolution "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "metadata": {
        "id": "CIvPQLzHpuSo"
      },
      "outputs": [],
      "source": [
        "class Convolution:\n",
        "    def __init__(self, W):\n",
        "        self.W = W"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-0ClQiqp3JO"
      },
      "source": [
        "## Pooling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBySGUTJjy39"
      },
      "source": [
        "# Network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVl0mOKYmKFr"
      },
      "source": [
        "## Multi-layer Net\n",
        "\n",
        "This network reach a accuarcy of 97%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "metadata": {
        "id": "HUem1Q5Dj09y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "class TwoLayerNet:\n",
        "    def __init__(self, input_size, hidden_sizes, output_size, weight_init_std=0.01, initParams=None, weight_decay_lambda=0, use_dropout=False, dropout_ratio=0) -> None:\n",
        "        \n",
        "        self.params = {}\n",
        "        self.weight_decay_lambda = weight_decay_lambda\n",
        "        self.hidden_layer_count = len(hidden_sizes)\n",
        "\n",
        "        if initParams is not None:\n",
        "            self.params = initParams\n",
        "        else:\n",
        "            self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_sizes[0])\n",
        "            self.params['b1'] = np.zeros(hidden_sizes[0])\n",
        "\n",
        "            for i in range(1, self.hidden_layer_count):\n",
        "                self.params[f'W{i+1}'] = weight_init_std * np.random.randn(hidden_sizes[i-1], hidden_sizes[i])\n",
        "                self.params[f'b{i+1}'] = np.zeros(hidden_sizes[i])\n",
        "\n",
        "            self.params[f'W{self.hidden_layer_count+1}'] = weight_init_std * np.random.randn(hidden_sizes[-1], output_size)\n",
        "            self.params[f'b{self.hidden_layer_count+1}'] = np.zeros(output_size)\n",
        "\n",
        "        self.layers = OrderedDict()\n",
        "        \n",
        "        for i in range(self.hidden_layer_count):\n",
        "            self.layers[f'Affine{i+1}'] = Affine(self.params[f'W{i+1}'], self.params[f'b{i+1}'])\n",
        "            self.layers[f'Relu{i+1}'] = Relu()\n",
        "            \n",
        "            if use_dropout:\n",
        "                self.layers[f'Dropout{i+1}'] = Dropout(dropout_ratio)\n",
        "\n",
        "        self.layers[f'Affine{self.hidden_layer_count+1}'] = Affine(self.params[f'W{self.hidden_layer_count+1}'], self.params[f'b{self.hidden_layer_count+1}'])\n",
        "\n",
        "        self.lastLayer = SoftmaxWithLoss(print_result = (not initParams == None))\n",
        "\n",
        "    def predict(self, x, train_flg=False):\n",
        "        for key, layer in self.layers.items():\n",
        "            if \"Dropout\" in key or \"BatchNorm\" in key:\n",
        "                x = layer.forward(x, train_flg)\n",
        "            else:\n",
        "                x = layer.forward(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x, train_flg=True)\n",
        "\n",
        "        return self.lastLayer.forward(y, t)\n",
        "\n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x, train_flg=False)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        \n",
        "        # Get the index of the maximum value. If one-shot is enabled the max value is 1\n",
        "        # For example, [[1, 0, 0], [0,0,1]] will be converted to [0, 2]\n",
        "        if t.ndim != 1: t = np.argmax(t, axis=1)\n",
        "\n",
        "        # if x.shape[0] <= 50:\n",
        "        #     print(\"Expected Anwser: \" + str(t))\n",
        "        #     print(\"Exact Anwser: \" + str(y))\n",
        "\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "\n",
        "        return accuracy\n",
        "    \n",
        "    def numerical_gradient(self, x, t):\n",
        "        loss_W = lambda W: self.loss(x, t)\n",
        "        \n",
        "        grads = {}\n",
        "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
        "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
        "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
        "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
        "        \n",
        "        return grads\n",
        "    \n",
        "    def gradient(self, x, t):\n",
        "        self.loss(x, t)\n",
        "\n",
        "        dout = 1\n",
        "        dout = self.lastLayer.backward(dout)\n",
        "\n",
        "        layers = list(self.layers.values())\n",
        "        layers.reverse()\n",
        "\n",
        "        for layer in layers:\n",
        "            dout = layer.backward(dout)\n",
        "\n",
        "        grads = {}\n",
        "        for i in range(self.hidden_layer_count + 1):\n",
        "            grads[f\"W{i+1}\"] = self.layers[f\"Affine{i+1}\"].dW + self.weight_decay_lambda * self.layers[f\"Affine{i+1}\"].W\n",
        "            grads[f\"b{i+1}\"] = self.layers[f\"Affine{i+1}\"].db\n",
        "\n",
        "        return grads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4ikKQHFmTLT"
      },
      "source": [
        "## CNN\n",
        "\n",
        "Convolutional neural networks is an enhanced version, which offers significant advantages, most notably the preservation of data shape. In previous neural network architectures, it was often necessary to convert two-dimensional arrays to one-dimensional arrays. \n",
        "\n",
        "With CNN, however, original-shaped data can be directly inputted into the network, without the need for additional preprocessing steps. As a result, CNNs outperform other neural network architectures, particularly when processing colored images.\n",
        "\n",
        "$\\nabla F=\\begin{pmatrix} yz \\ xz \\ xy \\end{pmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGTcZ_vTsQnY"
      },
      "source": [
        "# Training\n",
        "\n",
        "It's unusual for the accuracy to plateau after only a few epochs, especially if you're using a relatively large dataset.\n",
        "\n",
        "## Optimization\n",
        "\n",
        "* Use Dropout\n",
        "* Use weight decay\n",
        "* Enlarge the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "id": "b58Yf86LP0q4"
      },
      "outputs": [],
      "source": [
        "#@title Training Config { run: \"auto\" }\n",
        "\n",
        "scene = \"Production\" #@param [\"Train\", \"Production\"]\n",
        "network_type = \"MultiLayer\" #@param [\"MultiLayer\", \"CNN\"]\n",
        "learning_rate = 0.01 #@param {type:\"number\"}\n",
        "batch_size =100 #@param {type:\"number\"}\n",
        "hidden_layers = 2 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "layer_size = 100 #@param {type:\"number\"}\n",
        "iters_num = 20000 #@param {type:\"slider\", min:5000, max:100000, step:5000}\n",
        "optimizer_type = \"Momentum\" #@param [\"SGD\", \"Momentum\", \"AdaGrad\", \"Adam\"]\n",
        "train_data_source = \"MINIST + Custom\" #@param [\"MINIST\", \"MINIST + Custom\"]\n",
        "test_data_source = \"Custom\" #@param [\"MINIST\", \"Custom\", \"MINIST + Custom\"]\n",
        "weight_decay_lambda = 0 #@param {type:\"slider\", min:0, max:0.3, step:0.01}\n",
        "use_dropout = False #@param {type:\"boolean\"}\n",
        "dropout_ratio = 0.15 #@param {type:\"slider\", min:0, max:0.3, step:0.01}\n",
        "load_params = False #@param {type:\"boolean\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHkHWIfEssBH"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from colorama import Fore, Back, Style\n",
        "import math\n",
        "\n",
        "hidden_sizes = [layer_size for _ in range(hidden_layers)]\n",
        "\n",
        "def train(x_train, t_train, x_test, t_test, initParams=None):\n",
        "\n",
        "    network = TwoLayerNet(input_size=784, hidden_sizes=hidden_sizes, output_size=10, initParams=initParams, weight_decay_lambda=weight_decay_lambda, use_dropout=use_dropout, dropout_ratio=dropout_ratio)\n",
        "\n",
        "    optimizer = None\n",
        "\n",
        "    if optimizer_type == \"SGD\":\n",
        "        optimizer = SGD(lr=learning_rate)\n",
        "    elif optimizer_type == \"Momentum\":\n",
        "        optimizer = Momentum(lr=learning_rate)\n",
        "    elif optimizer_type == \"AdaGard\":\n",
        "        optimizer = SGD()\n",
        "    else:\n",
        "        optimizer = SGD()\n",
        "\n",
        "    train_size = x_train.shape[0] # 60000\n",
        "    train_loss_list = []\n",
        "    train_acc_list = []\n",
        "    test_acc_list = []\n",
        "\n",
        "    iter_per_epoch = max(train_size / batch_size, 1)\n",
        "\n",
        "    for i in range(iters_num):\n",
        "        batch_mask = np.random.choice(train_size, batch_size) # Select a batch_size between 0 - train_size\n",
        "\n",
        "        # Randomly select a part of data\n",
        "        x_batch = x_train[batch_mask]\n",
        "        t_batch = t_train[batch_mask]\n",
        "\n",
        "        if not initParams:\n",
        "            grads = network.gradient(x_batch, t_batch)\n",
        "            optimizer.update(network.params, grads)\n",
        "\n",
        "        loss = network.loss(x_batch, t_batch)\n",
        "        train_loss_list.append(loss)\n",
        "\n",
        "        # Only calcuate accuracy every epoch. All data passed in.\n",
        "        if i % math.floor(iter_per_epoch) == 0:\n",
        "            train_acc = network.accuracy(x_train, t_train)\n",
        "            test_acc = network.accuracy(x_test, t_test)\n",
        "            train_acc_list.append(train_acc)\n",
        "            test_acc_list.append(test_acc)\n",
        "            # print(train_acc, test_acc)\n",
        "    \n",
        "    epochs = range(len(train_acc_list))\n",
        "    print(epochs)\n",
        "    plt.plot(epochs, train_acc_list, label='Train Accuracy')\n",
        "    plt.plot(epochs, test_acc_list, label='Test Accuracy')\n",
        "    plt.title('Accuracy Change Per Epoch')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return network.params\n",
        "\n",
        "param_cache = None\n",
        "param_cache_dir = \"/content\"\n",
        "param_cache_file = param_cache_dir + \"/params.pkl\"\n",
        "\n",
        "if os.path.exists(param_cache_file):\n",
        "    with open(param_cache_file, 'rb') as f:\n",
        "        param_cache = pickle.load(f)\n",
        "\n",
        "minist_dataset = load_mnist(normalize=True, one_hot_label=True)\n",
        "custom_dataset = load_custom_data(one_hot_label=True)\n",
        "\n",
        "if train_data_source == \"MINIST\":\n",
        "    (x_train, t_train), _ = minist_dataset\n",
        "elif train_data_source == \"MINIST + Custom\":\n",
        "    (x_train_mnist, t_train_mnist), _ = minist_dataset\n",
        "    (x_train_custom, t_train_custom), _ = custom_dataset\n",
        "    x_train = np.concatenate((x_train_mnist, x_train_custom), axis=0)\n",
        "    t_train = np.concatenate((t_train_mnist, t_train_custom), axis=0)\n",
        "\n",
        "if test_data_source == \"MINIST\":\n",
        "    _, (x_test, t_test) = minist_dataset\n",
        "elif test_data_source == \"MINIST + Custom\":\n",
        "    _, (x_test_mnist, t_test_mnist) = minist_dataset\n",
        "    _, (x_test_custom, t_test_custom) = custom_dataset\n",
        "    x_test = np.concatenate((x_test_mnist, x_test_custom), axis=0)\n",
        "    t_test = np.concatenate((t_test_mnist, t_test_custom), axis=0)\n",
        "elif test_data_source == \"Custom\":\n",
        "    _ , (x_test, t_test) = custom_dataset\n",
        "\n",
        "print(Back.GREEN + \"● Entering \" + scene +  \" Mode...\" + Back.RESET)\n",
        "\n",
        "if scene == \"Train\":\n",
        "    initParams = None\n",
        "\n",
        "    if load_params and param_cache:\n",
        "        initParams = param_cache\n",
        "    \n",
        "    print(\"x_train size: \" + Fore.CYAN + str(x_train.shape) + Fore.RESET)\n",
        "    print(\"x_test size: \" + Fore.CYAN + str(x_test.shape) + Fore.RESET)\n",
        "    \n",
        "    params = train(x_train, t_train, x_test, t_test, initParams)\n",
        "\n",
        "    if not load_params or not os.path.exists(param_cache_file):\n",
        "        with open(param_cache_file, 'wb') as f:\n",
        "            pickle.dump(params, f, -1)\n",
        "            \n",
        "elif param_cache:\n",
        "    network = TwoLayerNet(input_size=784, hidden_sizes=hidden_sizes, output_size=10, initParams=param_cache, weight_decay_lambda=weight_decay_lambda)\n",
        "\n",
        "    print(\"Results: \" + Fore.YELLOW + str(np.argmax(network.predict(x_test), axis=1)) + Fore.RESET)\n",
        "    print(\"Expects: \" + Fore.GREEN + str(np.argmax(t_test, axis=1)))\n",
        "    \n",
        "else:\n",
        "    print(Fore.YELLOW + \"Please train params first\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFggngb-Zdlh"
      },
      "source": [
        "## Reference\n",
        "\n",
        "1. Saito Yasuhiro. Deep Learning from Scratch[M]. Japan: O'Reilly Japan, 2016.\n",
        "\n",
        "2. 管他叫大靖. (2021年05月24日). Softmax Loss 的推导及改进. 知乎专栏. (https://zhuanlan.zhihu.com/p/374018199).\n",
        "\n",
        "3. Khelifi Ahmed Aziz. Medium. Learn How to Write Markdown & LaTeX in The Jupyter Notebook (https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd)\n",
        "\n",
        "3. Jay Gupta. Medium. Going beyond 99% — MNIST Handwritten Digits Recognition (https://towardsdatascience.com/going-beyond-99-mnist-handwritten-digits-recognition-cfff96337392)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "RjRQLf1HjZZY",
        "428IuPKjnPPa",
        "V4ikKQHFmTLT"
      ],
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "18B-Fujnr7uDhfyERZzWHTI3-31anw5OH",
      "authorship_tag": "ABX9TyNausn3Z1Qwww4FATBHzELB",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}